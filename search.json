[{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"B-Safe r-shiny application interactive statistical software used analyse several safety endpoints using Bayesian (robust) Meta-Analytic Predictive (MAP) method. approach based works [1]. application present results via graphs, tables figures. application calculate meta-analytic predictive (MAP) prior robust MAP priors, assesses prior data conflict reports effective sample size / effective number events historical data. user able download output data / simulated results tabular form. error message expected input table contain required columns input parameters match intended analysis. aim testing validation plan test whether application working specified described functionality working intended. Test cases cover common use cases application aim ensuring calculations done application implemented properly. tests designed version 0.1 combination version 0.1.","code":""},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"requirement-specification","dir":"Articles","previous_headings":"","what":"Requirement Specification","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"application present results via graphs, tables figures. application calculate meta-analytic predictive (MAP) prior robust MAP priors, assesses prior data conflict reports effective sample size / effective number events historical data. user able download output data / simulated results tabular form. error message expected input table contain required columns input parameters match intended analysis.","code":""},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"purpose-and-scope","dir":"Articles","previous_headings":"","what":"Purpose and Scope","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"aim testing validation plan test whether application working specified described functionality working intended. Test cases cover common use cases application aim ensuring calculations done application implemented properly. tests designed version 0.1 combination version 0.1.","code":""},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"testing-and-requirement-strategy","dir":"Articles","previous_headings":"","what":"Testing and Requirement Strategy","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Software packages used application perform validation includes: Softwares Packages testing strategy based Input Testing Structural Testing. Input Testing performed investigate whether erroneous input user handled intended application. Structural Testing deals confirmation accuracy calculations done application. Different scenarios cater common cases simulated structural testing performed. code thresholds structural testing, well code simulate scenarios dependent package reviewed statisticians independently.","code":""},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"input-testing","dir":"Articles","previous_headings":"","what":"Input Testing","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"section describes verification procedure functionality B-Safe application. First, testing requirements strategies outlined. handling testing failures processes performing testing characterized. table gives brief overview parameters/variables user able set used within document. Definitions Variable case expected specifications met, test failed. conditions table 3 implementations needs tested actual testing full functionality B-Safe application can executed. Various test cases grouped together performed single action. example, test cases contain checking applications handling input values/characters. requirements tested via checkmate R package, allows warnings well errors guide user along error help fixing problem. addition required variables within approach tested specific required typing, also checkmate R package allows test certain boundaries variables well restricting inputs certain formats, e.g., csv. Setup .csv file Assumptions variables: Input Robust MAP Prior: Weakly-informative Prior weight numeric 0.010.01 0.990.99 New Trial Analysis: Number Patients selected ARM integer > 00 ≤\\le 200 Number Patients AE integer ≥\\ge00 ≤\\le number patients selected ARM Decision Making: Likelihood: Percentage Patients AE two integers specifying lower bound upper bound 0 100. MAP Prior: Percentage Patients AE two integers specifying lower bound upper bound 0 100. Robust MAP Prior: Percentage Patients AE two integers specifying lower bound upper bound 0 100. Posterior: Percentage Patients AE two integers specifying lower bound upper bound 0 100. Download Results: Number comparisons: integer 11 55 Test cases performed shown table . Different formats various input violated different test cases. false input, user shall informed error error displayed. test passed error message displayed. inputs including weakly-informative prior weight calculation Robust MAP Prior, number patients selected arm number patients AE new trial analysis, percentages making statistical inferences MAP Prior, Robust MAP Prior, Likelihood Posterior imputed slider. Different values along range sliders tested various scenarios. Setup .csv file Assumptions variables: Input Robust MAP Prior: Weakly-informative Prior weight numeric 0.010.01 0.990.99 Weakly-informative Prior mean exp scale numeric 0.010.01 33 New Trial Analysis: Number first occurrence event numeric 11 200200 Cumulative time occurrence first events numeric 11 10001000 Decision Making: Likelihood: area log(hazard) patients AE numeric within 99.8% (0.01% 99.9%) quantile. MAP Prior: area log(hazard) patients AE numeric within 99.8% (0.01% 99.9%) quantile. Robust MAP Prior: area log(hazard) patients AE within 99.8% (0.01% 99.9%) quantile. Posterior: area log(hazard) patients AE numeric within 99.8% (0.01% 99.9%) quantile. Download Results: Number comparisons: integer 11 55 inputs including weakly-informative prior weight calculation Robust MAP Prior, number patients selected arm number patients AE new trial analysis, percentages making statistical inferences MAP Prior, Robust MAP Prior, Likelihood Posterior imputed slider. Different values along range sliders tested various scenarios.","code":""},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"binary-endpoint","dir":"Articles","previous_headings":"","what":"Binary Endpoint","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Setup .csv file Assumptions variables: Input Robust MAP Prior: Weakly-informative Prior weight numeric 0.010.01 0.990.99 New Trial Analysis: Number Patients selected ARM integer > 00 ≤\\le 200 Number Patients AE integer ≥\\ge00 ≤\\le number patients selected ARM Decision Making: Likelihood: Percentage Patients AE two integers specifying lower bound upper bound 0 100. MAP Prior: Percentage Patients AE two integers specifying lower bound upper bound 0 100. Robust MAP Prior: Percentage Patients AE two integers specifying lower bound upper bound 0 100. Posterior: Percentage Patients AE two integers specifying lower bound upper bound 0 100. Download Results: Number comparisons: integer 11 55 Test cases performed shown table . Different formats various input violated different test cases. false input, user shall informed error error displayed. test passed error message displayed. inputs including weakly-informative prior weight calculation Robust MAP Prior, number patients selected arm number patients AE new trial analysis, percentages making statistical inferences MAP Prior, Robust MAP Prior, Likelihood Posterior imputed slider. Different values along range sliders tested various scenarios.","code":""},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"time-to-event-endpoint","dir":"Articles","previous_headings":"","what":"Time To Event Endpoint","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Setup .csv file Assumptions variables: Input Robust MAP Prior: Weakly-informative Prior weight numeric 0.010.01 0.990.99 Weakly-informative Prior mean exp scale numeric 0.010.01 33 New Trial Analysis: Number first occurrence event numeric 11 200200 Cumulative time occurrence first events numeric 11 10001000 Decision Making: Likelihood: area log(hazard) patients AE numeric within 99.8% (0.01% 99.9%) quantile. MAP Prior: area log(hazard) patients AE numeric within 99.8% (0.01% 99.9%) quantile. Robust MAP Prior: area log(hazard) patients AE within 99.8% (0.01% 99.9%) quantile. Posterior: area log(hazard) patients AE numeric within 99.8% (0.01% 99.9%) quantile. Download Results: Number comparisons: integer 11 55 inputs including weakly-informative prior weight calculation Robust MAP Prior, number patients selected arm number patients AE new trial analysis, percentages making statistical inferences MAP Prior, Robust MAP Prior, Likelihood Posterior imputed slider. Different values along range sliders tested various scenarios.","code":""},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"testing-framework-in-testthat","dir":"Articles","previous_headings":"","what":"Testing Framework in testthat","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"testing purpose testthat, thresholds defined scenarios, created beforehand saved separate file. well reference images scenario 03 created saved comparison. Moreover, due use Stan, also image comparison element saved. Moreover, parameter, used testing, also defined upfront saved file . Therefore package used ensure framework, commonly used stable. Hereby, testing setup replicates workflow application loading respective data, parameters well thresholds. First functions B-SAFE running run needed order ensure workflow. Therefore, calculations performed . Afterwards outputs different plots well tables displayed within application compared reference images, binaries images compared expected equal. setup file (), plots created saved (). executed, prior pixel wise comparison. plots created. () different created plot images binary tested (pixelwise comparison) reference images () ensure reproducibility. graphics check performed graphics scenario 3. Regarding tables displayed values, predefined scenarios loaded tested. scenarios output app tested, whether values within predefined boundaries whether displayed correct place. Therefore, tables double coded checked. displayed tables checked, values NA’s correct position. row (e.g. MAP prior summary statistics) appears two different displayed tables, check identical. framework either passes comparison values within certain tolerance, framework throw error values within threshold respective tolerance. details regarding thresholds tolerance see section Section 5.1. ESS summary statistics tested independently , reason see section Section 5.1. Moreover displayed tables checked, values NA’s correct position. row (e.g. MAP prior summary statistics) appears two different displayed tables, check identical. unit tests created ensure correct functionality helper functions. overall test coverage greater 80%.","code":""},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-testing","dir":"Articles","previous_headings":"","what":"Scenario Testing","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario testing used verify computations B-Safe Shiny application performs. purpose, various conditions set capture wide array possibilities set different parameter values. simulated scenario representation probable occurrence clinical trial. scenarios cover heterogeneous homogeneous data, large small borrowing historical information, high low robustification MAP prior. scenarios tested Adverse Event Incidence Proportion Exposure-Adjusted Adverse Event Rate. Following scenario briefly described. simulated data sets displayed section Section 5.1. information (e.g. level heterogeneity) please refer statistical analysis plan B-Safe. scenarios, except worst scenarios (2, 4, 12 13) pass without failures. Scenario 2, 4 12 issues stem problems integration within . developers informed fix upcoming version. Scenario 13 describes different treatment length. violation exchange ability assumption proportions tests fail analysis regular basis, therefore, excluded testing proportions. rates passed tests. scenarios tested withing certain threshold. code produce thresholds double coded. Instead thorough code review toke place. can found . script use function . Instead performs analysis using . independent source code review two statisticians, ensured validity. chapter, scenarios described section Section 6 incidence proportions section Section 7 exposure adjusted incidence rates respectively, simulated run B-SAFE app results cross-checked errors. testing procedure follows. fixed historical data scenario shown respective sections , run 1000 times generate set 1000 different MAP / robust MAP priors. set MAP / robust MAP priors, upper lower thresholds following summary statistics calculated taking 1% 99% quantile summary statistics observed 1000 simulation replicates. Summary statistics MAP / robust MAP priors : mean, SD, median, 95% Credible Intervals, ESS. 1000 MAP / robust MAP priors scenario subsequently updated corresponding (fixed) new trial data scenario, new data shown tables. Summary statistics likelihoods posterior distributions calculated, upper lower thresholds determined . code can found . Tests run using . test pass summary statistics (MAP prior, robust MAP prior, likelihood, posterior) lie within upper lower thresholds respective tolerance, fail otherwise. tolerances included adjust variability results. Due use within machine different MCMC result function calls. good scenarios (e.g. 1,3) threshold small (e.g. 1⋅10−41 \\cdot 10^{-4}). worse scenarios (e.g. 4,5), variability higher. decided use one tolerance binary (3⋅10−23 \\cdot 10^{-2}) another time event endpoint (8⋅10−28 \\cdot 10^{-2}). used highest rounded difference encountered couple test runs. tolerances used values except ESS. ESS/ENE decided 10% tolerance. However, seen observed minimum maximum values 1000 runs, cases absurdly high ESS/ENE reported. known issue, contacted authors. certain mixture components especially low weights, integration function malfunctions. Therefore, ESS/ENE exceeds number patients/events, MCMC sample drawn , three times. third attempt test fail. Moreover, certain scenarios (2, 4, 12), issue leads general exclusion test scenarios. general scenarios borrowing historical information strongly discouraged perform. values displayed, neither exploratory reporting feature B-SAFE. Nevertheless, coding reasons, still part array structure mentioned available (NA). scenario thresholds reviewed represent reasonable results regarding input data. section Section 6 Section 7 scenarios thresholds displayed. Tested within 98% quantiles +/- respective tolerance. minimum maximum 1000 iterations also displayed, show possible range, analysis dataset can result. three scripts part package . designed specifically testing strategy reviewed independently. scripts generates synthetic data mimics real-world studies. code can also found data set used testing various scenarios simulate using scenario specific variables. code can also found ","code":"# Function to simulate 1 study # nPat = Number of patients in each group # g1 = group 1 (treatment); g2 = group 2 (control) # dropout = 0_05: 5% dropout after time units of measure # accr = accrual time, is to be in regards to the hazard # NObsEvt = type 2 censoring, censor after NObsEvt number of events, probability of observing the event if < 1_ # accr_timepoint should include 0 and total accrual time_ # Pre-specify the censor type ahead of time   #' Simulate a study #' #' @param nPat #' @param hz #' @param dropout #' @param accr #' @param NObsEvt #' @param accr_method #' @param surv_method #' @param intensity #' @param accr_timepoint #' @param censor_type #' @param time_cutoff #' #' @return #' @export #' #' @examples SimStudy <- function(nPat = c(g1 = 100, g2 = 100),                      hz = c(g1 = 0.1, g2 = 0.2),                      dropout = c(rate = 0.05, time = 12),                      accr = 6,                      NObsEvt = 0.5,                      accr_method = \"Uniform\",                      surv_method = \"Exponential\",                      intensity = c(2, 6, 10),                      accr_timepoint = c(0, 2, 4, 6),                      censor_type = 1,                      time_cutoff = 18) {   N <- sum(nPat)   # Observed events either proportional ( < 100) or as absolute numbers   if (NObsEvt < 1) {     NObsEvt <- sum(nPat) * NObsEvt   }    # res: variable which stores the result output   # gID: 1 treatment 2 control   # ID: Subject   # Entry: Entry time according to accrual   # EventTime: Simulated Eventtime + Entry time   # ObsTime: Time observed (min(EventTime, CensorTime)-Entry)   # StudyTime: Timepoint in Study   # Eventindicator: 1 event observed, 0 censored   res <- matrix(     data = NA, nrow = N, ncol = 8,     dimnames = list(       ID = 1:N,       c(         \"gID\", \"ID\", \"Entry\", \"EventTime\",         \"ObsTime\", \"CensorTime\",         \"StudyTime\", \"EventIndicator\"       )     )   )   # ID and gID just from 1 to number of patients in each group   res[, \"ID\"] <- 1:N   res[, \"gID\"] <- c(rep(1, nPat[\"g1\"]), rep(2, nPat[\"g2\"]))    # Different methods for generating Enrollment Time   if (accr_method == \"Uniform\") {     res[, \"Entry\"] <- runif(N, 0, accr)   }    # Poisson accrual times   if (accr_method == \"Poisson\") {     rtlist <- lapply(intensity, function(x) rexp(N, x))     recruit_time <- c()     for (i in 1:length(intensity)) {       recruit_time_new <- c(accr_timepoint[i] + cumsum(rtlist[[i]][(accr_timepoint[i] + cumsum(rtlist[[i]])) < accr_timepoint[i + 1]]))       recruit_time <- c(recruit_time, recruit_time_new)     }     if (length(recruit_time) < N) {       enrollment <- c(recruit_time, runif((N - length(recruit_time)), min(accr_timepoint), max(accr_timepoint)))     } else {       enrollment <- recruit_time[1:N]     }     res[, \"Entry\"] <- enrollment   }    # Piecewise Uniform accrual times   if (accr_method == \"Piecewise Uniform\") {     recruit_time <- c()     for (i in 1:length(intensity)) {       n_part <- intensity[i] * diff(accr_timepoint)[i]       recruit_time_new <- runif(n_part, accr_timepoint[i], accr_timepoint[i + 1])       recruit_time <- c(recruit_time, recruit_time_new)     }     if (length(recruit_time) < N) {       enrollment <- c(recruit_time, runif((N - length(recruit_time)), min(accr_timepoint), max(accr_timepoint)))     } else {       enrollment <- recruit_time[1:N]     }     res[, \"Entry\"] <- enrollment   }    # Method for generating Survival Time   if (surv_method == \"Exponential\") {     for (i in 1:length(nPat)) {       SurvTimesG <- rexp(nPat[i], hz[i])       if (i == 1) {         SurvTimes <- SurvTimesG       } else {         SurvTimes <- c(SurvTimes, SurvTimesG)       }     }   }     # Event Times   res[, \"EventTime\"] <- res[, \"Entry\"] + SurvTimes    # Get rate parameter for exponential distributed censoring times   CensorRate <- if (dropout[\"rate\"] > 0) {     -log(1 - dropout[\"rate\"]) / dropout[\"time\"]   } else {     0   }    # Censoring times for all individuals, infinity if no censoring is applied   CensorTime <- if (dropout[\"rate\"] > 0) {     rexp(N, CensorRate)   } else {     rep(Inf, N)   }    res[, \"CensorTime\"] <- CensorTime + res[, \"Entry\"]    # Censor type 1, administrative censoring after cutoff time   if (censor_type == 1) {     evt_ind <- which(res[, \"EventTime\"] < res[, \"CensorTime\"] & res[, \"EventTime\"] < time_cutoff)     non_evt_ind <- which(!(res[, \"EventTime\"] < res[, \"CensorTime\"] & res[, \"EventTime\"] < time_cutoff))     res[evt_ind, \"EventIndicator\"] <- 1     res[non_evt_ind, \"EventIndicator\"] <- 0     res[evt_ind, \"ObsTime\"] <- res[evt_ind, \"EventTime\"] - res[evt_ind, \"Entry\"]     res[non_evt_ind, \"ObsTime\"] <- ifelse(res[non_evt_ind, \"CensorTime\"] < time_cutoff,       res[non_evt_ind, \"CensorTime\"] - res[non_evt_ind, \"Entry\"],       time_cutoff - res[non_evt_ind, \"Entry\"]     )     res[, \"StudyTime\"] <- res[, \"ObsTime\"] + res[, \"Entry\"]   }     # Type 2 censoring, censoring after number of observed events   if (censor_type == 2) {     # Introduce censoring indices     evt_ind <- which(res[, \"EventTime\"] < res[, \"CensorTime\"])     non_evt_ind <- which(res[, \"EventTime\"] >= res[, \"CensorTime\"])     res[evt_ind, \"EventIndicator\"] <- 1     res[non_evt_ind, \"EventIndicator\"] <- 0     res[evt_ind, \"ObsTime\"] <- res[evt_ind, \"EventTime\"] - res[evt_ind, \"Entry\"]     res[non_evt_ind, \"ObsTime\"] <- res[non_evt_ind, \"CensorTime\"] - res[non_evt_ind, \"Entry\"]     res[, \"StudyTime\"] <- res[, \"ObsTime\"] + res[, \"Entry\"]      type2_censortime <- sort(res[, \"StudyTime\"], decreasing = FALSE)[NObsEvt]     type2_censorind <- which(res[, \"StudyTime\"] > type2_censortime)     res[type2_censorind, \"StudyTime\"] <- type2_censortime     res[type2_censorind, \"EventIndicator\"] <- 0      new_censored_row_idx <- which(res[, \"StudyTime\"] == type2_censortime)      res[new_censored_row_idx, \"ObsTime\"] <- type2_censortime - res[new_censored_row_idx, \"Entry\"]   }    res <- as.data.frame(res)   return(res) } #' Simulate Test Data Set #' #' @param SimStudy_nPat #' @param SimStudy_hz #' @param SimStudy_dropout #' @param SimStudy_accr #' @param SimStudy_accr_method #' @param SimStudy_surv_method #' @param SimStudy_intensity #' @param SimStudy_accr_timepoint #' @param SimStudy_time_cutoff #' @param SimStudy_NObsEvt #' @param SimStudy_censor_type #' @param nStudy Number #' @param tau #' @param prior_data_conflict #' @param SAF_TOPIC Selected safety topic to analyze/the adverse event of interest #' @param pdc_hz #' @param diff_trt_length #' @param seed #' #' @return #' @export #' #' @examples SimTestData <- function(     SimStudy_nPat = c(g1 = 50, g2 = 100),     SimStudy_hz = c(g1 = 0.1, g2 = 0.2),     SimStudy_dropout = c(rate = 0.05, time = 18),     SimStudy_accr = 6,     SimStudy_accr_method = \"Uniform\",     SimStudy_surv_method = \"Exponential\",     SimStudy_intensity = c(2, 4, 6),     SimStudy_accr_timepoint = c(0, 2, 4, 6),     SimStudy_time_cutoff = 18,     SimStudy_NObsEvt = 100,     SimStudy_censor_type = 1,     nStudy = 5,     tau = 0,     prior_data_conflict = FALSE,     diff_trt_length = FALSE,     pdc_hz = c(g1 = 0.05, g2 = 0.5),     SAF_TOPIC = \"Example\",     seed = 123) {   res <- array(     data = NA, dim = c(nStudy, 5, 2),     dimnames = list(       STUDYID = c(1:nStudy),       c(\"HIST\", \"ARM\", \"N\", \"N_WITH_AE\", \"TOT_EXP\"),       c(\"g1\", \"g2\")     )   )    res[1:(nStudy - 1), \"HIST\", ] <- 1   res[nStudy, \"HIST\", ] <- 0    res[, \"ARM\", \"g1\"] <- 1   res[, \"ARM\", \"g2\"] <- 2    res[, \"N\", \"g1\"] <- SimStudy_nPat[\"g1\"]   res[, \"N\", \"g2\"] <- SimStudy_nPat[\"g2\"]    # intiualize the list to save the data   res_SimStudy <- list()    #   if (!is.na(seed)) {     set.seed(seed)   }    # For prior Data conflict, simulate n-1 similar and 1 different trial   if (prior_data_conflict == TRUE) {     nStudy <- nStudy - 1   }    # Simulate sutdies    if (diff_trt_length == TRUE) {     SimStudy_time_cutoff_set <- (c(0.5, 0.5, 1, 1, 1.5, 1.5) + 1) * 12   } else {     SimStudy_time_cutoff_set <- SimStudy_time_cutoff   }      for (i in 1:nStudy) {     if (tau > 0) {       SimStudy_hz <- exp(log(SimStudy_hz) + rnorm(2, mean = 0, sd = tau))     }     if (diff_trt_length == FALSE) {       res_SimStudy[[i]] <- SimStudy(         nPat = SimStudy_nPat,         hz = SimStudy_hz,         dropout = SimStudy_dropout,         accr = SimStudy_accr,         accr_method = SimStudy_accr_method,         surv_method = SimStudy_surv_method,         intensity = SimStudy_intensity,         accr_timepoint = SimStudy_accr_timepoint,         time_cutoff = SimStudy_time_cutoff_set,         NObsEvt = SimStudy_NObsEvt,         censor_type = SimStudy_censor_type       )     } else {       # treatment_length = runif(1, 0.5, 1.5)       # SimStudy_time_cutoff = (treatment_length + 1) * 12       # SimStudy_time_cutoff_set = c(SimStudy_time_cutoff_set, treatment_length)       res_SimStudy[[i]] <- SimStudy(         nPat = SimStudy_nPat,         hz = SimStudy_hz,         dropout = SimStudy_dropout,         accr = SimStudy_accr,         accr_method = SimStudy_accr_method,         surv_method = SimStudy_surv_method,         intensity = SimStudy_intensity,         accr_timepoint = SimStudy_accr_timepoint,         time_cutoff = SimStudy_time_cutoff_set[i],         NObsEvt = SimStudy_NObsEvt,         censor_type = SimStudy_censor_type       )     }   }    # Simulate the different trial   if (prior_data_conflict == TRUE) {     nStudy <- nStudy + 1      res_SimStudy[[nStudy]] <- SimStudy(       nPat = SimStudy_nPat,       hz = pdc_hz,       dropout = SimStudy_dropout,       accr = SimStudy_accr,       accr_method = SimStudy_accr_method,       surv_method = SimStudy_surv_method,       intensity = SimStudy_intensity,       accr_timepoint = SimStudy_accr_timepoint,       time_cutoff = SimStudy_time_cutoff,       NObsEvt = SimStudy_NObsEvt,       censor_type = SimStudy_censor_type     )   }    for (s in 1:nStudy) {     for (g in 1:2) {       res[s, \"TOT_EXP\", g] <-         sum(res_SimStudy[[s]][res_SimStudy[[s]]$gID == g, ]$ObsTime)        res[s, \"N_WITH_AE\", g] <-         sum(res_SimStudy[[s]][res_SimStudy[[s]]$gID == g, ]$EventIndicator)     }   }    res_df <- as.data.frame(rbind(res[, , 1], res[, , 2]))   row.names(res_df) <- c(paste0(c(1:nStudy), \"_g1\"), paste0(c(1:nStudy), \"_g2\"))   res_df$STUDYID <- c(paste0(\"Study#\", 1:nStudy), paste0(\"Study#\", 1:nStudy))   res_df[res_df$ARM == 1, \"ARM\"] <- \"g1\"   res_df[res_df$ARM == 2, \"ARM\"] <- \"g2\"   res_df$SAF_TOPIC <- SAF_TOPIC   res_df <- res_df[, c(     \"STUDYID\", \"HIST\", \"ARM\", \"N\",     \"SAF_TOPIC\", \"N_WITH_AE\", \"TOT_EXP\"   )]     if (diff_trt_length == TRUE) {     res_df$LENGTH <- NA     for (i in 1:nStudy) {       res_df[res_df$STUDYID == paste0(\"Study#\", i), ]$LENGTH <- round(SimStudy_time_cutoff_set[i] / 12 * 365)     }   }    res_df$TREAT <- SAF_TOPIC    return(res_df) }"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"sec-simulation-and-testing-of-scenarios","dir":"Articles","previous_headings":"","what":"Simulation and Testing of Scenarios","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"chapter, scenarios described section Section 6 incidence proportions section Section 7 exposure adjusted incidence rates respectively, simulated run B-SAFE app results cross-checked errors. testing procedure follows. fixed historical data scenario shown respective sections , run 1000 times generate set 1000 different MAP / robust MAP priors. set MAP / robust MAP priors, upper lower thresholds following summary statistics calculated taking 1% 99% quantile summary statistics observed 1000 simulation replicates. Summary statistics MAP / robust MAP priors : mean, SD, median, 95% Credible Intervals, ESS. 1000 MAP / robust MAP priors scenario subsequently updated corresponding (fixed) new trial data scenario, new data shown tables. Summary statistics likelihoods posterior distributions calculated, upper lower thresholds determined . code can found . Tests run using . test pass summary statistics (MAP prior, robust MAP prior, likelihood, posterior) lie within upper lower thresholds respective tolerance, fail otherwise. tolerances included adjust variability results. Due use within machine different MCMC result function calls. good scenarios (e.g. 1,3) threshold small (e.g. 1⋅10−41 \\cdot 10^{-4}). worse scenarios (e.g. 4,5), variability higher. decided use one tolerance binary (3⋅10−23 \\cdot 10^{-2}) another time event endpoint (8⋅10−28 \\cdot 10^{-2}). used highest rounded difference encountered couple test runs. tolerances used values except ESS. ESS/ENE decided 10% tolerance. However, seen observed minimum maximum values 1000 runs, cases absurdly high ESS/ENE reported. known issue, contacted authors. certain mixture components especially low weights, integration function malfunctions. Therefore, ESS/ENE exceeds number patients/events, MCMC sample drawn , three times. third attempt test fail. Moreover, certain scenarios (2, 4, 12), issue leads general exclusion test scenarios. general scenarios borrowing historical information strongly discouraged perform. values displayed, neither exploratory reporting feature B-SAFE. Nevertheless, coding reasons, still part array structure mentioned available (NA). scenario thresholds reviewed represent reasonable results regarding input data. section Section 6 Section 7 scenarios thresholds displayed. Tested within 98% quantiles +/- respective tolerance. minimum maximum 1000 iterations also displayed, show possible range, analysis dataset can result.","code":""},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"code-of-data-simulation","dir":"Articles","previous_headings":"","what":"Code of Data Simulation","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"three scripts part package . designed specifically testing strategy reviewed independently. scripts generates synthetic data mimics real-world studies. code can also found data set used testing various scenarios simulate using scenario specific variables. code can also found ","code":"# Function to simulate 1 study # nPat = Number of patients in each group # g1 = group 1 (treatment); g2 = group 2 (control) # dropout = 0_05: 5% dropout after time units of measure # accr = accrual time, is to be in regards to the hazard # NObsEvt = type 2 censoring, censor after NObsEvt number of events, probability of observing the event if < 1_ # accr_timepoint should include 0 and total accrual time_ # Pre-specify the censor type ahead of time   #' Simulate a study #' #' @param nPat #' @param hz #' @param dropout #' @param accr #' @param NObsEvt #' @param accr_method #' @param surv_method #' @param intensity #' @param accr_timepoint #' @param censor_type #' @param time_cutoff #' #' @return #' @export #' #' @examples SimStudy <- function(nPat = c(g1 = 100, g2 = 100),                      hz = c(g1 = 0.1, g2 = 0.2),                      dropout = c(rate = 0.05, time = 12),                      accr = 6,                      NObsEvt = 0.5,                      accr_method = \"Uniform\",                      surv_method = \"Exponential\",                      intensity = c(2, 6, 10),                      accr_timepoint = c(0, 2, 4, 6),                      censor_type = 1,                      time_cutoff = 18) {   N <- sum(nPat)   # Observed events either proportional ( < 100) or as absolute numbers   if (NObsEvt < 1) {     NObsEvt <- sum(nPat) * NObsEvt   }    # res: variable which stores the result output   # gID: 1 treatment 2 control   # ID: Subject   # Entry: Entry time according to accrual   # EventTime: Simulated Eventtime + Entry time   # ObsTime: Time observed (min(EventTime, CensorTime)-Entry)   # StudyTime: Timepoint in Study   # Eventindicator: 1 event observed, 0 censored   res <- matrix(     data = NA, nrow = N, ncol = 8,     dimnames = list(       ID = 1:N,       c(         \"gID\", \"ID\", \"Entry\", \"EventTime\",         \"ObsTime\", \"CensorTime\",         \"StudyTime\", \"EventIndicator\"       )     )   )   # ID and gID just from 1 to number of patients in each group   res[, \"ID\"] <- 1:N   res[, \"gID\"] <- c(rep(1, nPat[\"g1\"]), rep(2, nPat[\"g2\"]))    # Different methods for generating Enrollment Time   if (accr_method == \"Uniform\") {     res[, \"Entry\"] <- runif(N, 0, accr)   }    # Poisson accrual times   if (accr_method == \"Poisson\") {     rtlist <- lapply(intensity, function(x) rexp(N, x))     recruit_time <- c()     for (i in 1:length(intensity)) {       recruit_time_new <- c(accr_timepoint[i] + cumsum(rtlist[[i]][(accr_timepoint[i] + cumsum(rtlist[[i]])) < accr_timepoint[i + 1]]))       recruit_time <- c(recruit_time, recruit_time_new)     }     if (length(recruit_time) < N) {       enrollment <- c(recruit_time, runif((N - length(recruit_time)), min(accr_timepoint), max(accr_timepoint)))     } else {       enrollment <- recruit_time[1:N]     }     res[, \"Entry\"] <- enrollment   }    # Piecewise Uniform accrual times   if (accr_method == \"Piecewise Uniform\") {     recruit_time <- c()     for (i in 1:length(intensity)) {       n_part <- intensity[i] * diff(accr_timepoint)[i]       recruit_time_new <- runif(n_part, accr_timepoint[i], accr_timepoint[i + 1])       recruit_time <- c(recruit_time, recruit_time_new)     }     if (length(recruit_time) < N) {       enrollment <- c(recruit_time, runif((N - length(recruit_time)), min(accr_timepoint), max(accr_timepoint)))     } else {       enrollment <- recruit_time[1:N]     }     res[, \"Entry\"] <- enrollment   }    # Method for generating Survival Time   if (surv_method == \"Exponential\") {     for (i in 1:length(nPat)) {       SurvTimesG <- rexp(nPat[i], hz[i])       if (i == 1) {         SurvTimes <- SurvTimesG       } else {         SurvTimes <- c(SurvTimes, SurvTimesG)       }     }   }     # Event Times   res[, \"EventTime\"] <- res[, \"Entry\"] + SurvTimes    # Get rate parameter for exponential distributed censoring times   CensorRate <- if (dropout[\"rate\"] > 0) {     -log(1 - dropout[\"rate\"]) / dropout[\"time\"]   } else {     0   }    # Censoring times for all individuals, infinity if no censoring is applied   CensorTime <- if (dropout[\"rate\"] > 0) {     rexp(N, CensorRate)   } else {     rep(Inf, N)   }    res[, \"CensorTime\"] <- CensorTime + res[, \"Entry\"]    # Censor type 1, administrative censoring after cutoff time   if (censor_type == 1) {     evt_ind <- which(res[, \"EventTime\"] < res[, \"CensorTime\"] & res[, \"EventTime\"] < time_cutoff)     non_evt_ind <- which(!(res[, \"EventTime\"] < res[, \"CensorTime\"] & res[, \"EventTime\"] < time_cutoff))     res[evt_ind, \"EventIndicator\"] <- 1     res[non_evt_ind, \"EventIndicator\"] <- 0     res[evt_ind, \"ObsTime\"] <- res[evt_ind, \"EventTime\"] - res[evt_ind, \"Entry\"]     res[non_evt_ind, \"ObsTime\"] <- ifelse(res[non_evt_ind, \"CensorTime\"] < time_cutoff,       res[non_evt_ind, \"CensorTime\"] - res[non_evt_ind, \"Entry\"],       time_cutoff - res[non_evt_ind, \"Entry\"]     )     res[, \"StudyTime\"] <- res[, \"ObsTime\"] + res[, \"Entry\"]   }     # Type 2 censoring, censoring after number of observed events   if (censor_type == 2) {     # Introduce censoring indices     evt_ind <- which(res[, \"EventTime\"] < res[, \"CensorTime\"])     non_evt_ind <- which(res[, \"EventTime\"] >= res[, \"CensorTime\"])     res[evt_ind, \"EventIndicator\"] <- 1     res[non_evt_ind, \"EventIndicator\"] <- 0     res[evt_ind, \"ObsTime\"] <- res[evt_ind, \"EventTime\"] - res[evt_ind, \"Entry\"]     res[non_evt_ind, \"ObsTime\"] <- res[non_evt_ind, \"CensorTime\"] - res[non_evt_ind, \"Entry\"]     res[, \"StudyTime\"] <- res[, \"ObsTime\"] + res[, \"Entry\"]      type2_censortime <- sort(res[, \"StudyTime\"], decreasing = FALSE)[NObsEvt]     type2_censorind <- which(res[, \"StudyTime\"] > type2_censortime)     res[type2_censorind, \"StudyTime\"] <- type2_censortime     res[type2_censorind, \"EventIndicator\"] <- 0      new_censored_row_idx <- which(res[, \"StudyTime\"] == type2_censortime)      res[new_censored_row_idx, \"ObsTime\"] <- type2_censortime - res[new_censored_row_idx, \"Entry\"]   }    res <- as.data.frame(res)   return(res) } #' Simulate Test Data Set #' #' @param SimStudy_nPat #' @param SimStudy_hz #' @param SimStudy_dropout #' @param SimStudy_accr #' @param SimStudy_accr_method #' @param SimStudy_surv_method #' @param SimStudy_intensity #' @param SimStudy_accr_timepoint #' @param SimStudy_time_cutoff #' @param SimStudy_NObsEvt #' @param SimStudy_censor_type #' @param nStudy Number #' @param tau #' @param prior_data_conflict #' @param SAF_TOPIC Selected safety topic to analyze/the adverse event of interest #' @param pdc_hz #' @param diff_trt_length #' @param seed #' #' @return #' @export #' #' @examples SimTestData <- function(     SimStudy_nPat = c(g1 = 50, g2 = 100),     SimStudy_hz = c(g1 = 0.1, g2 = 0.2),     SimStudy_dropout = c(rate = 0.05, time = 18),     SimStudy_accr = 6,     SimStudy_accr_method = \"Uniform\",     SimStudy_surv_method = \"Exponential\",     SimStudy_intensity = c(2, 4, 6),     SimStudy_accr_timepoint = c(0, 2, 4, 6),     SimStudy_time_cutoff = 18,     SimStudy_NObsEvt = 100,     SimStudy_censor_type = 1,     nStudy = 5,     tau = 0,     prior_data_conflict = FALSE,     diff_trt_length = FALSE,     pdc_hz = c(g1 = 0.05, g2 = 0.5),     SAF_TOPIC = \"Example\",     seed = 123) {   res <- array(     data = NA, dim = c(nStudy, 5, 2),     dimnames = list(       STUDYID = c(1:nStudy),       c(\"HIST\", \"ARM\", \"N\", \"N_WITH_AE\", \"TOT_EXP\"),       c(\"g1\", \"g2\")     )   )    res[1:(nStudy - 1), \"HIST\", ] <- 1   res[nStudy, \"HIST\", ] <- 0    res[, \"ARM\", \"g1\"] <- 1   res[, \"ARM\", \"g2\"] <- 2    res[, \"N\", \"g1\"] <- SimStudy_nPat[\"g1\"]   res[, \"N\", \"g2\"] <- SimStudy_nPat[\"g2\"]    # intiualize the list to save the data   res_SimStudy <- list()    #   if (!is.na(seed)) {     set.seed(seed)   }    # For prior Data conflict, simulate n-1 similar and 1 different trial   if (prior_data_conflict == TRUE) {     nStudy <- nStudy - 1   }    # Simulate sutdies    if (diff_trt_length == TRUE) {     SimStudy_time_cutoff_set <- (c(0.5, 0.5, 1, 1, 1.5, 1.5) + 1) * 12   } else {     SimStudy_time_cutoff_set <- SimStudy_time_cutoff   }      for (i in 1:nStudy) {     if (tau > 0) {       SimStudy_hz <- exp(log(SimStudy_hz) + rnorm(2, mean = 0, sd = tau))     }     if (diff_trt_length == FALSE) {       res_SimStudy[[i]] <- SimStudy(         nPat = SimStudy_nPat,         hz = SimStudy_hz,         dropout = SimStudy_dropout,         accr = SimStudy_accr,         accr_method = SimStudy_accr_method,         surv_method = SimStudy_surv_method,         intensity = SimStudy_intensity,         accr_timepoint = SimStudy_accr_timepoint,         time_cutoff = SimStudy_time_cutoff_set,         NObsEvt = SimStudy_NObsEvt,         censor_type = SimStudy_censor_type       )     } else {       # treatment_length = runif(1, 0.5, 1.5)       # SimStudy_time_cutoff = (treatment_length + 1) * 12       # SimStudy_time_cutoff_set = c(SimStudy_time_cutoff_set, treatment_length)       res_SimStudy[[i]] <- SimStudy(         nPat = SimStudy_nPat,         hz = SimStudy_hz,         dropout = SimStudy_dropout,         accr = SimStudy_accr,         accr_method = SimStudy_accr_method,         surv_method = SimStudy_surv_method,         intensity = SimStudy_intensity,         accr_timepoint = SimStudy_accr_timepoint,         time_cutoff = SimStudy_time_cutoff_set[i],         NObsEvt = SimStudy_NObsEvt,         censor_type = SimStudy_censor_type       )     }   }    # Simulate the different trial   if (prior_data_conflict == TRUE) {     nStudy <- nStudy + 1      res_SimStudy[[nStudy]] <- SimStudy(       nPat = SimStudy_nPat,       hz = pdc_hz,       dropout = SimStudy_dropout,       accr = SimStudy_accr,       accr_method = SimStudy_accr_method,       surv_method = SimStudy_surv_method,       intensity = SimStudy_intensity,       accr_timepoint = SimStudy_accr_timepoint,       time_cutoff = SimStudy_time_cutoff,       NObsEvt = SimStudy_NObsEvt,       censor_type = SimStudy_censor_type     )   }    for (s in 1:nStudy) {     for (g in 1:2) {       res[s, \"TOT_EXP\", g] <-         sum(res_SimStudy[[s]][res_SimStudy[[s]]$gID == g, ]$ObsTime)        res[s, \"N_WITH_AE\", g] <-         sum(res_SimStudy[[s]][res_SimStudy[[s]]$gID == g, ]$EventIndicator)     }   }    res_df <- as.data.frame(rbind(res[, , 1], res[, , 2]))   row.names(res_df) <- c(paste0(c(1:nStudy), \"_g1\"), paste0(c(1:nStudy), \"_g2\"))   res_df$STUDYID <- c(paste0(\"Study#\", 1:nStudy), paste0(\"Study#\", 1:nStudy))   res_df[res_df$ARM == 1, \"ARM\"] <- \"g1\"   res_df[res_df$ARM == 2, \"ARM\"] <- \"g2\"   res_df$SAF_TOPIC <- SAF_TOPIC   res_df <- res_df[, c(     \"STUDYID\", \"HIST\", \"ARM\", \"N\",     \"SAF_TOPIC\", \"N_WITH_AE\", \"TOT_EXP\"   )]     if (diff_trt_length == TRUE) {     res_df$LENGTH <- NA     for (i in 1:nStudy) {       res_df[res_df$STUDYID == paste0(\"Study#\", i), ]$LENGTH <- round(SimStudy_time_cutoff_set[i] / 12 * 365)     }   }    res_df$TREAT <- SAF_TOPIC    return(res_df) }"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"sec-binary-endpoint-results","dir":"Articles","previous_headings":"","what":"Binary Endpoint results","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"best case scenario, almost events observed, long follow time large number historical trials available. characteristics thresholds simulation table : Scenario 2 describes test case scenario binary endpoint strong prior data conflict historical current trials. characteristics scenario includes censoring current trial, noise, events observed, homogeneous historical data heavy prior data conflict. characteristics thresholds simulation table : Scenario 3 describes binary endpoint realistic situation dropout rate 5%, 2% tau, events observed 90% power, homogeneous historical data planned prior data conflict. characteristics thresholds simulation table : Scenario 4 describes binary endpoint worst case scenario huge censoring trial, huge noise data, low number events observed 90% power, heterogeneous historical data huge data conflict. characteristics thresholds simulation table : Scenario 5 describes binary endpoint medium heterogeneous scenario historical data, moderate noise 5% tau, moderate censoring 5%, events observed 90% power planned prior data conflict. characteristics thresholds simulation table : Scenario 6 describes binary endpoint scenario huge dropout within current trial, noise 2% tau, event observed 90% power, homogeneous data planned prior data conflict. characteristics thresholds simulation table : Scenario 7 describes binary endpoint scenario high heterogeneity historical data, moderate censoring current trial, moderate noise 2% tau, events observed 90% power, planned prior data conflict. characteristics thresholds simulation table : Scenario 8 describes binary endpoint bad scenario huge censoring current trial, huge noise, little events observed current trial, heterogeneous historical data planned prior data conflict. characteristics thresholds simulation table : Scenario 9 describes binary endpoint good scenario low censoring current trial, small noise, majority events observed homogeneous historical data. characteristics thresholds simulation table : Scenario 10 describes binary endpoint favored control scenario censoring current trial, noise, events observed, homogeneous historical data, heavy prior data conflict hazard ratio favor control group. characteristics thresholds simulation table : Scenario 11 describes binary endpoint realistic situation study continued regardless proposed number events observed. Characteristics scenario includes drop rate 5%, noise 5% tau, homogeneous historical data planned prior data conflict planned. characteristics thresholds simulation table : Scenario 12 describes binary endpoint scenario worst case scenario (scenario 4) continued till end proposed study duration. scenario characteristics includes huge censoring, huge noise, little events observed, heterogeneous historical huge prior data conflict. characteristics thresholds simulation table : Scenario 13 describes good scenario different treatment length. violation exchange ability assumption proportions tests fail analysis regular basis, therefore, excluded testing. characteristics thresholds simulation table :","code":"# Scen1 SimTestData(   SimStudy_nPat = c(g1 = 300, g2 = 300),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0, time = 12),   SimStudy_accr = 1,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 0.999,   SimStudy_censor_type = 2,   nStudy = 10,   tau = 0,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen1\",   seed = 1699874539 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1   Study#1    1  g1 300     Scen1       299 2828.715 Scen1 2_g1   Study#2    1  g1 300     Scen1       299 2882.367 Scen1 3_g1   Study#3    1  g1 300     Scen1       299 3236.408 Scen1 4_g1   Study#4    1  g1 300     Scen1       299 3085.252 Scen1 5_g1   Study#5    1  g1 300     Scen1       299 2984.353 Scen1 6_g1   Study#6    1  g1 300     Scen1       299 3305.953 Scen1 7_g1   Study#7    1  g1 300     Scen1       299 2975.530 Scen1 8_g1   Study#8    1  g1 300     Scen1       299 3103.969 Scen1 9_g1   Study#9    1  g1 300     Scen1       299 2763.876 Scen1 10_g1 Study#10    0  g1 300     Scen1       299 3044.691 Scen1 1_g2   Study#1    1  g2 300     Scen1       300 1466.836 Scen1 2_g2   Study#2    1  g2 300     Scen1       300 1604.556 Scen1 3_g2   Study#3    1  g2 300     Scen1       300 1428.295 Scen1 4_g2   Study#4    1  g2 300     Scen1       300 1472.222 Scen1 5_g2   Study#5    1  g2 300     Scen1       300 1678.517 Scen1 6_g2   Study#6    1  g2 300     Scen1       300 1504.812 Scen1 7_g2   Study#7    1  g2 300     Scen1       300 1626.479 Scen1 8_g2   Study#8    1  g2 300     Scen1       300 1480.283 Scen1 9_g2   Study#9    1  g2 300     Scen1       300 1644.251 Scen1 10_g2 Study#10    0  g2 300     Scen1       300 1519.465 Scen1 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed Best case scenario Scen01.csv    g1 Incidence proportion    Scen01 1699874539                    pool        tau heterog  ESS rob_weight nta_event nta_npat Best case scenario TRUE HalfNormal   Small elir       0.05       194      200 # Scen2 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.3),   SimStudy_dropout = c(rate = 0, time = 12),   SimStudy_accr = 1,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 0.9,   SimStudy_censor_type = 2,   nStudy = 10,   tau = 0.01,   prior_data_conflict = TRUE,   pdc_hz = c(g1 = 0.4, g2 = 0.05),   SAF_TOPIC = \"Scen2\",   seed = 1701611344 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP TREAT 1_g1   Study#1    1  g1 200     Scen2       161 1530.2128 Scen2 2_g1   Study#2    1  g1 200     Scen2       162 1528.7454 Scen2 3_g1   Study#3    1  g1 200     Scen2       160 1660.3443 Scen2 4_g1   Study#4    1  g1 200     Scen2       161 1840.7538 Scen2 5_g1   Study#5    1  g1 200     Scen2       162 1605.1504 Scen2 6_g1   Study#6    1  g1 200     Scen2       164 1496.5477 Scen2 7_g1   Study#7    1  g1 200     Scen2       161 1622.6838 Scen2 8_g1   Study#8    1  g1 200     Scen2       162 1575.8092 Scen2 9_g1   Study#9    1  g1 200     Scen2       161 1638.6499 Scen2 10_g1 Study#10    0  g1 200     Scen2       200  439.5240 Scen2 1_g2   Study#1    1  g2 200     Scen2       199  723.4652 Scen2 2_g2   Study#2    1  g2 200     Scen2       198  725.3088 Scen2 3_g2   Study#3    1  g2 200     Scen2       200  633.6027 Scen2 4_g2   Study#4    1  g2 200     Scen2       199  631.2705 Scen2 5_g2   Study#5    1  g2 200     Scen2       198  701.9784 Scen2 6_g2   Study#6    1  g2 200     Scen2       196  705.4184 Scen2 7_g2   Study#7    1  g2 200     Scen2       199  680.0606 Scen2 8_g2   Study#8    1  g2 200     Scen2       198  704.2055 Scen2 9_g2   Study#9    1  g2 200     Scen2       199  727.2699 Scen2 10_g2 Study#10    0  g2 200     Scen2       160 3910.1011 Scen2 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic Strong Prior Data Conflict Scen02.csv    g1 Incidence proportion    Scen02                                  seed pool        tau  heterog  ESS rob_weight Strong Prior Data Conflict 1701611344 TRUE HalfNormal Moderate elir        0.8                            nta_event nta_npat Strong Prior Data Conflict       199      200 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.02,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen3\",   seed = 1701621384 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen3        30 282.8273 Scen3 2_g1 Study#2    1  g1 200     Scen3        35 345.5776 Scen3 3_g1 Study#3    1  g1 200     Scen3        32 355.6786 Scen3 4_g1 Study#4    1  g1 200     Scen3        35 409.5392 Scen3 5_g1 Study#5    1  g1 200     Scen3        36 207.1725 Scen3 6_g1 Study#6    0  g1 200     Scen3        40 291.3027 Scen3 1_g2 Study#1    1  g2 200     Scen3        60 259.6821 Scen3 2_g2 Study#2    1  g2 200     Scen3        52 268.0612 Scen3 3_g2 Study#3    1  g2 200     Scen3        57 237.5458 Scen3 4_g2 Study#4    1  g2 200     Scen3        54 359.4474 Scen3 5_g2 Study#5    1  g2 200     Scen3        52 170.1687 Scen3 6_g2 Study#6    0  g2 200     Scen3        50 266.0703 Scen3 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed Realisitic Scenarios Scen03.csv    g1 Incidence proportion    Scen03 1701621384                      pool        tau     heterog  ESS rob_weight nta_event Realisitic Scenarios TRUE HalfNormal Substantial elir       0.25        31                      nta_npat Realisitic Scenarios      200 SimTestData(   SimStudy_nPat = c(g1 = 50, g2 = 100),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.2, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 112,   SimStudy_censor_type = 2,   nStudy = 3,   tau = 0.15,   prior_data_conflict = TRUE,   pdc_hz = c(g1 = 0.05, g2 = 0.1),   SAF_TOPIC = \"Scen4\",   seed = 1701626683 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1  50     Scen4        28 197.5691 Scen4 2_g1 Study#2    1  g1  50     Scen4        27 237.3923 Scen4 3_g1 Study#3    0  g1  50     Scen4        23 425.0280 Scen4 1_g2 Study#1    1  g2 100     Scen4        73 283.1671 Scen4 2_g2 Study#2    1  g2 100     Scen4        73 334.8827 Scen4 3_g2 Study#3    0  g2 100     Scen4        70 750.5857 Scen4 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed Worst Case Scenario Scen04.csv    g1 Incidence proportion    Scen04 1701626683                     pool        tau    heterog  ESS rob_weight nta_event Worst Case Scenario TRUE HalfNormal Very Large elir       0.99        27                     nta_npat Worst Case Scenario       50 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 1,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.05,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen5\",   seed = 1701628373 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen5        24 336.2761 Scen5 2_g1 Study#2    1  g1 200     Scen5        35 328.5856 Scen5 3_g1 Study#3    1  g1 200     Scen5        26 319.0432 Scen5 4_g1 Study#4    1  g1 200     Scen5        36 319.4839 Scen5 5_g1 Study#5    1  g1 200     Scen5        39 282.5063 Scen5 6_g1 Study#6    0  g1 200     Scen5        25 289.3660 Scen5 1_g2 Study#1    1  g2 200     Scen5        68 295.3881 Scen5 2_g2 Study#2    1  g2 200     Scen5        55 310.0651 Scen5 3_g2 Study#3    1  g2 200     Scen5        63 290.2667 Scen5 4_g2 Study#4    1  g2 200     Scen5        54 288.7203 Scen5 5_g2 Study#5    1  g2 200     Scen5        52 283.8704 Scen5 6_g2 Study#6    0  g2 200     Scen5        66 263.6880 Scen5 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed Worst Case Scenario Scen04.csv    g1 Incidence proportion    Scen04 1701626683                     pool        tau    heterog  ESS rob_weight nta_event Worst Case Scenario TRUE HalfNormal Very Large elir       0.99        27                     nta_npat Worst Case Scenario       50 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.3, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 95,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.02,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen6\",   seed = 1701628373 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen6        26 291.6589 Scen6 2_g1 Study#2    1  g1 200     Scen6        27 225.3005 Scen6 3_g1 Study#3    1  g1 200     Scen6        28 292.3146 Scen6 4_g1 Study#4    1  g1 200     Scen6        28 268.4692 Scen6 5_g1 Study#5    1  g1 200     Scen6        40 212.6690 Scen6 6_g1 Study#6    0  g1 200     Scen6        24 198.0645 Scen6 1_g2 Study#1    1  g2 200     Scen6        56 226.4060 Scen6 2_g2 Study#2    1  g2 200     Scen6        52 203.6631 Scen6 3_g2 Study#3    1  g2 200     Scen6        55 255.6490 Scen6 4_g2 Study#4    1  g2 200     Scen6        47 221.9167 Scen6 5_g2 Study#5    1  g2 200     Scen6        45 238.6339 Scen6 6_g2 Study#6    0  g2 200     Scen6        54 219.5831 Scen6 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed pool High Dropout Scen06.csv    g1 Incidence proportion    Scen06 1701628373 TRUE                     tau  heterog  ESS rob_weight nta_event nta_npat High Dropout HalfNormal Moderate elir       0.14        31      200 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.15,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen7\",   seed = 1701416989 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen7        32 222.47360 Scen7 2_g1 Study#2    1  g1 200     Scen7        27 270.34094 Scen7 3_g1 Study#3    1  g1 200     Scen7        32 271.08747 Scen7 4_g1 Study#4    1  g1 200     Scen7        36 116.93497 Scen7 5_g1 Study#5    1  g1 200     Scen7        29 111.37228 Scen7 6_g1 Study#6    0  g1 200     Scen7        23 163.68689 Scen7 1_g2 Study#1    1  g2 200     Scen7        59 189.49417 Scen7 2_g2 Study#2    1  g2 200     Scen7        62 284.62991 Scen7 3_g2 Study#3    1  g2 200     Scen7        58 210.80011 Scen7 4_g2 Study#4    1  g2 200     Scen7        56  77.53109 Scen7 5_g2 Study#5    1  g2 200     Scen7        62 118.22857 Scen7 6_g2 Study#6    0  g2 200     Scen7        68  97.68813 Scen7 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed High Heterogeneity Scen07.csv    g1 Incidence proportion    Scen07 1701416989                    pool        tau    heterog  ESS rob_weight nta_event High Heterogeneity TRUE HalfNormal Very Large elir        0.2        35                    nta_npat High Heterogeneity      200 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.3, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.15,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen8\",   seed = 1701652217 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen8        22 297.7669 Scen8 2_g1 Study#2    1  g1 200     Scen8        31 298.1832 Scen8 3_g1 Study#3    1  g1 200     Scen8        21 307.9312 Scen8 4_g1 Study#4    1  g1 200     Scen8        21 379.2739 Scen8 5_g1 Study#5    1  g1 200     Scen8        28 405.2051 Scen8 6_g1 Study#6    0  g1 200     Scen8        30 368.8481 Scen8 1_g2 Study#1    1  g2 200     Scen8        53 234.0924 Scen8 2_g2 Study#2    1  g2 200     Scen8        45 226.9392 Scen8 3_g2 Study#3    1  g2 200     Scen8        55 211.8717 Scen8 4_g2 Study#4    1  g2 200     Scen8        56 348.7668 Scen8 5_g2 Study#5    1  g2 200     Scen8        46 375.9676 Scen8 6_g2 Study#6    0  g2 200     Scen8        45 284.3348 Scen8 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed pool Bad Scenario Scen08.csv    g1 Incidence proportion    Scen08 1701652217 TRUE                     tau heterog  ESS rob_weight nta_event nta_npat Bad Scenario HalfNormal   Large elir        0.2        25      200 SimTestData(   SimStudy_nPat = c(g1 = 300, g2 = 300),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 24,   SimStudy_NObsEvt = 0.999,   SimStudy_censor_type = 1,   nStudy = 8,   tau = 0.01,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen9\",   seed = 1701655293 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 300     Scen9       260 2838.989 Scen9 2_g1 Study#2    1  g1 300     Scen9       259 2624.533 Scen9 3_g1 Study#3    1  g1 300     Scen9       251 2933.272 Scen9 4_g1 Study#4    1  g1 300     Scen9       251 2984.729 Scen9 5_g1 Study#5    1  g1 300     Scen9       259 2667.259 Scen9 6_g1 Study#6    1  g1 300     Scen9       265 2774.955 Scen9 7_g1 Study#7    1  g1 300     Scen9       255 2665.750 Scen9 8_g1 Study#8    0  g1 300     Scen9       261 2691.265 Scen9 1_g2 Study#1    1  g2 300     Scen9       292 1550.852 Scen9 2_g2 Study#2    1  g2 300     Scen9       295 1646.227 Scen9 3_g2 Study#3    1  g2 300     Scen9       297 1360.433 Scen9 4_g2 Study#4    1  g2 300     Scen9       289 1676.768 Scen9 5_g2 Study#5    1  g2 300     Scen9       294 1678.219 Scen9 6_g2 Study#6    1  g2 300     Scen9       295 1628.496 Scen9 7_g2 Study#7    1  g2 300     Scen9       295 1628.708 Scen9 8_g2 Study#8    0  g2 300     Scen9       295 1486.654 Scen9 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed pool Good Scenario Scen09.csv    g1 Incidence proportion    Scen09 1701655293 TRUE                      tau heterog  ESS rob_weight nta_event nta_npat Good Scenario HalfNormal   Small elir       0.05       175      200 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.2, g2 = 0.1),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.02,   prior_data_conflict = TRUE,   pdc_hz = 1.2,   SAF_TOPIC = \"Scen10\",   seed = 1701673095 ) Warning in rexp(nPat[i], hz[i]): NAs produced STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE    TOT_EXP  TREAT 1_g1 Study#1    1  g1 200    Scen10        54 234.482445 Scen10 2_g1 Study#2    1  g1 200    Scen10        42 200.954605 Scen10 3_g1 Study#3    1  g1 200    Scen10        59 233.239862 Scen10 4_g1 Study#4    1  g1 200    Scen10        51 204.363002 Scen10 5_g1 Study#5    1  g1 200    Scen10        52 170.728016 Scen10 6_g1 Study#6    0  g1 200    Scen10        93  -6.482995 Scen10 1_g2 Study#1    1  g2 200    Scen10        36 282.421760 Scen10 2_g2 Study#2    1  g2 200    Scen10        46 214.300246 Scen10 3_g2 Study#3    1  g2 200    Scen10        32 318.335395 Scen10 4_g2 Study#4    1  g2 200    Scen10        37 243.939964 Scen10 5_g2 Study#5    1  g2 200    Scen10        39 244.166712 Scen10 6_g2 Study#6    0  g2 200    Scen10        NA         NA Scen10 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed pool Favored Control Scen10.csv    g1 Incidence proportion    Scen10 1701673095 TRUE                        tau heterog  ESS rob_weight nta_event nta_npat Favored Control HalfNormal   Small elir        0.6       175      200 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 24,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 1,   nStudy = 6,   tau = 0.02,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen11\",   seed = 1701876972 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP  TREAT 1_g1 Study#1    1  g1 200    Scen11       170 1871.1930 Scen11 2_g1 Study#2    1  g1 200    Scen11       173 1630.1105 Scen11 3_g1 Study#3    1  g1 200    Scen11       168 1744.6636 Scen11 4_g1 Study#4    1  g1 200    Scen11       170 1904.9560 Scen11 5_g1 Study#5    1  g1 200    Scen11       166 1748.6775 Scen11 6_g1 Study#6    0  g1 200    Scen11       162 1879.6921 Scen11 1_g2 Study#1    1  g2 200    Scen11       191  910.6017 Scen11 2_g2 Study#2    1  g2 200    Scen11       192  957.8531 Scen11 3_g2 Study#3    1  g2 200    Scen11       196  922.9765 Scen11 4_g2 Study#4    1  g2 200    Scen11       198  927.3806 Scen11 5_g2 Study#5    1  g2 200    Scen11       193 1027.3669 Scen11 6_g2 Study#6    0  g2 200    Scen11       196 1068.8192 Scen11 [1] \"With those values our newly created MAP Prior has been updated:\" csv group Continued Study Duration with Realistic Setting Scen11.csv    g1                                                             analysis saf_topic Continued Study Duration with Realistic Setting Incidence proportion    Scen11                                                       seed pool        tau Continued Study Duration with Realistic Setting 1701876972 TRUE HalfNormal                                                 heterog  ESS rob_weight Continued Study Duration with Realistic Setting   Small elir       0.05                                                 nta_event nta_npat Continued Study Duration with Realistic Setting       170      200 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = NA,   SimStudy_NObsEvt = 400,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.15,   prior_data_conflict = TRUE,   pdc_hz = c(g1 = 0.05, g2 = 0.1),   SAF_TOPIC = \"Scen12\",   seed = 1701878308 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP  TREAT 1_g1 Study#1    1  g1 200    Scen12       193 2145.2002 Scen12 2_g1 Study#2    1  g1 200    Scen12       189 2026.7007 Scen12 3_g1 Study#3    1  g1 200    Scen12       192 2099.1503 Scen12 4_g1 Study#4    1  g1 200    Scen12       193 2200.2265 Scen12 5_g1 Study#5    1  g1 200    Scen12       189 2060.4879 Scen12 6_g1 Study#6    0  g1 200    Scen12       193 3214.6233 Scen12 1_g2 Study#1    1  g2 200    Scen12       196  927.0819 Scen12 2_g2 Study#2    1  g2 200    Scen12       193 1097.0120 Scen12 3_g2 Study#3    1  g2 200    Scen12       196 1112.5535 Scen12 4_g2 Study#4    1  g2 200    Scen12       195 1489.9002 Scen12 5_g2 Study#5    1  g2 200    Scen12       198 1575.7302 Scen12 6_g2 Study#6    0  g2 200    Scen12       191 1811.5262 Scen12 [1] \"With those values our newly created MAP Prior has been updated:\" csv group Continued Study Duration with Worst Setting Scen12.csv    g1                                                         analysis saf_topic Continued Study Duration with Worst Setting Incidence proportion    Scen12                                                   seed pool        tau heterog Continued Study Duration with Worst Setting 1701878308 TRUE HalfNormal   Large                                              ESS rob_weight nta_event nta_npat Continued Study Duration with Worst Setting elir        0.5        30      200 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 1,   nStudy = 6,   tau = 0.02,   prior_data_conflict = FALSE,   diff_trt_length = TRUE,   pdc_hz = NA,   SAF_TOPIC = \"Scen13\",   seed = 1718356066 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP LENGTH  TREAT 1_g1 Study#1    1  g1 200    Scen13       151 1566.6752    548 Scen13 2_g1 Study#2    1  g1 200    Scen13       150 1494.2869    548 Scen13 3_g1 Study#3    1  g1 200    Scen13       174 1599.3219    730 Scen13 4_g1 Study#4    1  g1 200    Scen13       173 1799.5756    730 Scen13 5_g1 Study#5    1  g1 200    Scen13       185 1708.9438    912 Scen13 6_g1 Study#6    0  g1 200    Scen13       186 1681.4362    912 Scen13 1_g2 Study#1    1  g2 200    Scen13       185  897.0528    548 Scen13 2_g2 Study#2    1  g2 200    Scen13       185  872.8150    548 Scen13 3_g2 Study#3    1  g2 200    Scen13       191  943.3266    730 Scen13 4_g2 Study#4    1  g2 200    Scen13       194  872.9301    730 Scen13 5_g2 Study#5    1  g2 200    Scen13       192 1047.1975    912 Scen13 6_g2 Study#6    0  g2 200    Scen13       198  861.1155    912 Scen13 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic Different treatment length Scen13.csv    g1 Incidence proportion    Scen13                                  seed pool        tau heterog  ESS rob_weight Different treatment length 1718356066 TRUE HalfNormal   Large elir        0.1                            nta_event nta_npat Different treatment length       186      200"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-1---best-case-scenario","dir":"Articles","previous_headings":"","what":"Scenario 1 - Best Case Scenario","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"best case scenario, almost events observed, long follow time large number historical trials available. characteristics thresholds simulation table :","code":"# Scen1 SimTestData(   SimStudy_nPat = c(g1 = 300, g2 = 300),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0, time = 12),   SimStudy_accr = 1,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 0.999,   SimStudy_censor_type = 2,   nStudy = 10,   tau = 0,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen1\",   seed = 1699874539 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1   Study#1    1  g1 300     Scen1       299 2828.715 Scen1 2_g1   Study#2    1  g1 300     Scen1       299 2882.367 Scen1 3_g1   Study#3    1  g1 300     Scen1       299 3236.408 Scen1 4_g1   Study#4    1  g1 300     Scen1       299 3085.252 Scen1 5_g1   Study#5    1  g1 300     Scen1       299 2984.353 Scen1 6_g1   Study#6    1  g1 300     Scen1       299 3305.953 Scen1 7_g1   Study#7    1  g1 300     Scen1       299 2975.530 Scen1 8_g1   Study#8    1  g1 300     Scen1       299 3103.969 Scen1 9_g1   Study#9    1  g1 300     Scen1       299 2763.876 Scen1 10_g1 Study#10    0  g1 300     Scen1       299 3044.691 Scen1 1_g2   Study#1    1  g2 300     Scen1       300 1466.836 Scen1 2_g2   Study#2    1  g2 300     Scen1       300 1604.556 Scen1 3_g2   Study#3    1  g2 300     Scen1       300 1428.295 Scen1 4_g2   Study#4    1  g2 300     Scen1       300 1472.222 Scen1 5_g2   Study#5    1  g2 300     Scen1       300 1678.517 Scen1 6_g2   Study#6    1  g2 300     Scen1       300 1504.812 Scen1 7_g2   Study#7    1  g2 300     Scen1       300 1626.479 Scen1 8_g2   Study#8    1  g2 300     Scen1       300 1480.283 Scen1 9_g2   Study#9    1  g2 300     Scen1       300 1644.251 Scen1 10_g2 Study#10    0  g2 300     Scen1       300 1519.465 Scen1 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed Best case scenario Scen01.csv    g1 Incidence proportion    Scen01 1699874539                    pool        tau heterog  ESS rob_weight nta_event nta_npat Best case scenario TRUE HalfNormal   Small elir       0.05       194      200"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-2---strong-prior-data-conflict","dir":"Articles","previous_headings":"","what":"Scenario 2 - Strong Prior Data Conflict","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 2 describes test case scenario binary endpoint strong prior data conflict historical current trials. characteristics scenario includes censoring current trial, noise, events observed, homogeneous historical data heavy prior data conflict. characteristics thresholds simulation table :","code":"# Scen2 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.3),   SimStudy_dropout = c(rate = 0, time = 12),   SimStudy_accr = 1,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 0.9,   SimStudy_censor_type = 2,   nStudy = 10,   tau = 0.01,   prior_data_conflict = TRUE,   pdc_hz = c(g1 = 0.4, g2 = 0.05),   SAF_TOPIC = \"Scen2\",   seed = 1701611344 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP TREAT 1_g1   Study#1    1  g1 200     Scen2       161 1530.2128 Scen2 2_g1   Study#2    1  g1 200     Scen2       162 1528.7454 Scen2 3_g1   Study#3    1  g1 200     Scen2       160 1660.3443 Scen2 4_g1   Study#4    1  g1 200     Scen2       161 1840.7538 Scen2 5_g1   Study#5    1  g1 200     Scen2       162 1605.1504 Scen2 6_g1   Study#6    1  g1 200     Scen2       164 1496.5477 Scen2 7_g1   Study#7    1  g1 200     Scen2       161 1622.6838 Scen2 8_g1   Study#8    1  g1 200     Scen2       162 1575.8092 Scen2 9_g1   Study#9    1  g1 200     Scen2       161 1638.6499 Scen2 10_g1 Study#10    0  g1 200     Scen2       200  439.5240 Scen2 1_g2   Study#1    1  g2 200     Scen2       199  723.4652 Scen2 2_g2   Study#2    1  g2 200     Scen2       198  725.3088 Scen2 3_g2   Study#3    1  g2 200     Scen2       200  633.6027 Scen2 4_g2   Study#4    1  g2 200     Scen2       199  631.2705 Scen2 5_g2   Study#5    1  g2 200     Scen2       198  701.9784 Scen2 6_g2   Study#6    1  g2 200     Scen2       196  705.4184 Scen2 7_g2   Study#7    1  g2 200     Scen2       199  680.0606 Scen2 8_g2   Study#8    1  g2 200     Scen2       198  704.2055 Scen2 9_g2   Study#9    1  g2 200     Scen2       199  727.2699 Scen2 10_g2 Study#10    0  g2 200     Scen2       160 3910.1011 Scen2 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic Strong Prior Data Conflict Scen02.csv    g1 Incidence proportion    Scen02                                  seed pool        tau  heterog  ESS rob_weight Strong Prior Data Conflict 1701611344 TRUE HalfNormal Moderate elir        0.8                            nta_event nta_npat Strong Prior Data Conflict       199      200"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-3---realistic-scenario","dir":"Articles","previous_headings":"","what":"Scenario 3 - Realistic Scenario","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 3 describes binary endpoint realistic situation dropout rate 5%, 2% tau, events observed 90% power, homogeneous historical data planned prior data conflict. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.02,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen3\",   seed = 1701621384 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen3        30 282.8273 Scen3 2_g1 Study#2    1  g1 200     Scen3        35 345.5776 Scen3 3_g1 Study#3    1  g1 200     Scen3        32 355.6786 Scen3 4_g1 Study#4    1  g1 200     Scen3        35 409.5392 Scen3 5_g1 Study#5    1  g1 200     Scen3        36 207.1725 Scen3 6_g1 Study#6    0  g1 200     Scen3        40 291.3027 Scen3 1_g2 Study#1    1  g2 200     Scen3        60 259.6821 Scen3 2_g2 Study#2    1  g2 200     Scen3        52 268.0612 Scen3 3_g2 Study#3    1  g2 200     Scen3        57 237.5458 Scen3 4_g2 Study#4    1  g2 200     Scen3        54 359.4474 Scen3 5_g2 Study#5    1  g2 200     Scen3        52 170.1687 Scen3 6_g2 Study#6    0  g2 200     Scen3        50 266.0703 Scen3 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed Realisitic Scenarios Scen03.csv    g1 Incidence proportion    Scen03 1701621384                      pool        tau     heterog  ESS rob_weight nta_event Realisitic Scenarios TRUE HalfNormal Substantial elir       0.25        31                      nta_npat Realisitic Scenarios      200"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-4---worst-case-scenario","dir":"Articles","previous_headings":"","what":"Scenario 4 - Worst Case Scenario","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 4 describes binary endpoint worst case scenario huge censoring trial, huge noise data, low number events observed 90% power, heterogeneous historical data huge data conflict. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 50, g2 = 100),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.2, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 112,   SimStudy_censor_type = 2,   nStudy = 3,   tau = 0.15,   prior_data_conflict = TRUE,   pdc_hz = c(g1 = 0.05, g2 = 0.1),   SAF_TOPIC = \"Scen4\",   seed = 1701626683 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1  50     Scen4        28 197.5691 Scen4 2_g1 Study#2    1  g1  50     Scen4        27 237.3923 Scen4 3_g1 Study#3    0  g1  50     Scen4        23 425.0280 Scen4 1_g2 Study#1    1  g2 100     Scen4        73 283.1671 Scen4 2_g2 Study#2    1  g2 100     Scen4        73 334.8827 Scen4 3_g2 Study#3    0  g2 100     Scen4        70 750.5857 Scen4 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed Worst Case Scenario Scen04.csv    g1 Incidence proportion    Scen04 1701626683                     pool        tau    heterog  ESS rob_weight nta_event Worst Case Scenario TRUE HalfNormal Very Large elir       0.99        27                     nta_npat Worst Case Scenario       50"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-5---heterogeneous-data-medium","dir":"Articles","previous_headings":"","what":"Scenario 5 - Heterogeneous Data (Medium)","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 5 describes binary endpoint medium heterogeneous scenario historical data, moderate noise 5% tau, moderate censoring 5%, events observed 90% power planned prior data conflict. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 1,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.05,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen5\",   seed = 1701628373 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen5        24 336.2761 Scen5 2_g1 Study#2    1  g1 200     Scen5        35 328.5856 Scen5 3_g1 Study#3    1  g1 200     Scen5        26 319.0432 Scen5 4_g1 Study#4    1  g1 200     Scen5        36 319.4839 Scen5 5_g1 Study#5    1  g1 200     Scen5        39 282.5063 Scen5 6_g1 Study#6    0  g1 200     Scen5        25 289.3660 Scen5 1_g2 Study#1    1  g2 200     Scen5        68 295.3881 Scen5 2_g2 Study#2    1  g2 200     Scen5        55 310.0651 Scen5 3_g2 Study#3    1  g2 200     Scen5        63 290.2667 Scen5 4_g2 Study#4    1  g2 200     Scen5        54 288.7203 Scen5 5_g2 Study#5    1  g2 200     Scen5        52 283.8704 Scen5 6_g2 Study#6    0  g2 200     Scen5        66 263.6880 Scen5 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed Worst Case Scenario Scen04.csv    g1 Incidence proportion    Scen04 1701626683                     pool        tau    heterog  ESS rob_weight nta_event Worst Case Scenario TRUE HalfNormal Very Large elir       0.99        27                     nta_npat Worst Case Scenario       50"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-6---high-dropout","dir":"Articles","previous_headings":"","what":"Scenario 6 - High Dropout","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 6 describes binary endpoint scenario huge dropout within current trial, noise 2% tau, event observed 90% power, homogeneous data planned prior data conflict. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.3, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 95,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.02,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen6\",   seed = 1701628373 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen6        26 291.6589 Scen6 2_g1 Study#2    1  g1 200     Scen6        27 225.3005 Scen6 3_g1 Study#3    1  g1 200     Scen6        28 292.3146 Scen6 4_g1 Study#4    1  g1 200     Scen6        28 268.4692 Scen6 5_g1 Study#5    1  g1 200     Scen6        40 212.6690 Scen6 6_g1 Study#6    0  g1 200     Scen6        24 198.0645 Scen6 1_g2 Study#1    1  g2 200     Scen6        56 226.4060 Scen6 2_g2 Study#2    1  g2 200     Scen6        52 203.6631 Scen6 3_g2 Study#3    1  g2 200     Scen6        55 255.6490 Scen6 4_g2 Study#4    1  g2 200     Scen6        47 221.9167 Scen6 5_g2 Study#5    1  g2 200     Scen6        45 238.6339 Scen6 6_g2 Study#6    0  g2 200     Scen6        54 219.5831 Scen6 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed pool High Dropout Scen06.csv    g1 Incidence proportion    Scen06 1701628373 TRUE                     tau  heterog  ESS rob_weight nta_event nta_npat High Dropout HalfNormal Moderate elir       0.14        31      200"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-7---high-heterogeneity","dir":"Articles","previous_headings":"","what":"Scenario 7 - High Heterogeneity","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 7 describes binary endpoint scenario high heterogeneity historical data, moderate censoring current trial, moderate noise 2% tau, events observed 90% power, planned prior data conflict. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.15,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen7\",   seed = 1701416989 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen7        32 222.47360 Scen7 2_g1 Study#2    1  g1 200     Scen7        27 270.34094 Scen7 3_g1 Study#3    1  g1 200     Scen7        32 271.08747 Scen7 4_g1 Study#4    1  g1 200     Scen7        36 116.93497 Scen7 5_g1 Study#5    1  g1 200     Scen7        29 111.37228 Scen7 6_g1 Study#6    0  g1 200     Scen7        23 163.68689 Scen7 1_g2 Study#1    1  g2 200     Scen7        59 189.49417 Scen7 2_g2 Study#2    1  g2 200     Scen7        62 284.62991 Scen7 3_g2 Study#3    1  g2 200     Scen7        58 210.80011 Scen7 4_g2 Study#4    1  g2 200     Scen7        56  77.53109 Scen7 5_g2 Study#5    1  g2 200     Scen7        62 118.22857 Scen7 6_g2 Study#6    0  g2 200     Scen7        68  97.68813 Scen7 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed High Heterogeneity Scen07.csv    g1 Incidence proportion    Scen07 1701416989                    pool        tau    heterog  ESS rob_weight nta_event High Heterogeneity TRUE HalfNormal Very Large elir        0.2        35                    nta_npat High Heterogeneity      200"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-8---bad-scenario","dir":"Articles","previous_headings":"","what":"Scenario 8 - Bad Scenario","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 8 describes binary endpoint bad scenario huge censoring current trial, huge noise, little events observed current trial, heterogeneous historical data planned prior data conflict. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.3, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.15,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen8\",   seed = 1701652217 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen8        22 297.7669 Scen8 2_g1 Study#2    1  g1 200     Scen8        31 298.1832 Scen8 3_g1 Study#3    1  g1 200     Scen8        21 307.9312 Scen8 4_g1 Study#4    1  g1 200     Scen8        21 379.2739 Scen8 5_g1 Study#5    1  g1 200     Scen8        28 405.2051 Scen8 6_g1 Study#6    0  g1 200     Scen8        30 368.8481 Scen8 1_g2 Study#1    1  g2 200     Scen8        53 234.0924 Scen8 2_g2 Study#2    1  g2 200     Scen8        45 226.9392 Scen8 3_g2 Study#3    1  g2 200     Scen8        55 211.8717 Scen8 4_g2 Study#4    1  g2 200     Scen8        56 348.7668 Scen8 5_g2 Study#5    1  g2 200     Scen8        46 375.9676 Scen8 6_g2 Study#6    0  g2 200     Scen8        45 284.3348 Scen8 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed pool Bad Scenario Scen08.csv    g1 Incidence proportion    Scen08 1701652217 TRUE                     tau heterog  ESS rob_weight nta_event nta_npat Bad Scenario HalfNormal   Large elir        0.2        25      200"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-9---good-scenario","dir":"Articles","previous_headings":"","what":"Scenario 9 - Good Scenario","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 9 describes binary endpoint good scenario low censoring current trial, small noise, majority events observed homogeneous historical data. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 300, g2 = 300),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 24,   SimStudy_NObsEvt = 0.999,   SimStudy_censor_type = 1,   nStudy = 8,   tau = 0.01,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen9\",   seed = 1701655293 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 300     Scen9       260 2838.989 Scen9 2_g1 Study#2    1  g1 300     Scen9       259 2624.533 Scen9 3_g1 Study#3    1  g1 300     Scen9       251 2933.272 Scen9 4_g1 Study#4    1  g1 300     Scen9       251 2984.729 Scen9 5_g1 Study#5    1  g1 300     Scen9       259 2667.259 Scen9 6_g1 Study#6    1  g1 300     Scen9       265 2774.955 Scen9 7_g1 Study#7    1  g1 300     Scen9       255 2665.750 Scen9 8_g1 Study#8    0  g1 300     Scen9       261 2691.265 Scen9 1_g2 Study#1    1  g2 300     Scen9       292 1550.852 Scen9 2_g2 Study#2    1  g2 300     Scen9       295 1646.227 Scen9 3_g2 Study#3    1  g2 300     Scen9       297 1360.433 Scen9 4_g2 Study#4    1  g2 300     Scen9       289 1676.768 Scen9 5_g2 Study#5    1  g2 300     Scen9       294 1678.219 Scen9 6_g2 Study#6    1  g2 300     Scen9       295 1628.496 Scen9 7_g2 Study#7    1  g2 300     Scen9       295 1628.708 Scen9 8_g2 Study#8    0  g2 300     Scen9       295 1486.654 Scen9 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed pool Good Scenario Scen09.csv    g1 Incidence proportion    Scen09 1701655293 TRUE                      tau heterog  ESS rob_weight nta_event nta_npat Good Scenario HalfNormal   Small elir       0.05       175      200"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-10---favoured-control","dir":"Articles","previous_headings":"","what":"Scenario 10 - Favoured Control","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 10 describes binary endpoint favored control scenario censoring current trial, noise, events observed, homogeneous historical data, heavy prior data conflict hazard ratio favor control group. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.2, g2 = 0.1),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.02,   prior_data_conflict = TRUE,   pdc_hz = 1.2,   SAF_TOPIC = \"Scen10\",   seed = 1701673095 ) Warning in rexp(nPat[i], hz[i]): NAs produced STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE    TOT_EXP  TREAT 1_g1 Study#1    1  g1 200    Scen10        54 234.482445 Scen10 2_g1 Study#2    1  g1 200    Scen10        42 200.954605 Scen10 3_g1 Study#3    1  g1 200    Scen10        59 233.239862 Scen10 4_g1 Study#4    1  g1 200    Scen10        51 204.363002 Scen10 5_g1 Study#5    1  g1 200    Scen10        52 170.728016 Scen10 6_g1 Study#6    0  g1 200    Scen10        93  -6.482995 Scen10 1_g2 Study#1    1  g2 200    Scen10        36 282.421760 Scen10 2_g2 Study#2    1  g2 200    Scen10        46 214.300246 Scen10 3_g2 Study#3    1  g2 200    Scen10        32 318.335395 Scen10 4_g2 Study#4    1  g2 200    Scen10        37 243.939964 Scen10 5_g2 Study#5    1  g2 200    Scen10        39 244.166712 Scen10 6_g2 Study#6    0  g2 200    Scen10        NA         NA Scen10 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic       seed pool Favored Control Scen10.csv    g1 Incidence proportion    Scen10 1701673095 TRUE                        tau heterog  ESS rob_weight nta_event nta_npat Favored Control HalfNormal   Small elir        0.6       175      200"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-11---continued-study-duration-with-realistic-setting","dir":"Articles","previous_headings":"","what":"Scenario 11 - Continued study duration with Realistic Setting","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 11 describes binary endpoint realistic situation study continued regardless proposed number events observed. Characteristics scenario includes drop rate 5%, noise 5% tau, homogeneous historical data planned prior data conflict planned. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 24,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 1,   nStudy = 6,   tau = 0.02,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen11\",   seed = 1701876972 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP  TREAT 1_g1 Study#1    1  g1 200    Scen11       170 1871.1930 Scen11 2_g1 Study#2    1  g1 200    Scen11       173 1630.1105 Scen11 3_g1 Study#3    1  g1 200    Scen11       168 1744.6636 Scen11 4_g1 Study#4    1  g1 200    Scen11       170 1904.9560 Scen11 5_g1 Study#5    1  g1 200    Scen11       166 1748.6775 Scen11 6_g1 Study#6    0  g1 200    Scen11       162 1879.6921 Scen11 1_g2 Study#1    1  g2 200    Scen11       191  910.6017 Scen11 2_g2 Study#2    1  g2 200    Scen11       192  957.8531 Scen11 3_g2 Study#3    1  g2 200    Scen11       196  922.9765 Scen11 4_g2 Study#4    1  g2 200    Scen11       198  927.3806 Scen11 5_g2 Study#5    1  g2 200    Scen11       193 1027.3669 Scen11 6_g2 Study#6    0  g2 200    Scen11       196 1068.8192 Scen11 [1] \"With those values our newly created MAP Prior has been updated:\" csv group Continued Study Duration with Realistic Setting Scen11.csv    g1                                                             analysis saf_topic Continued Study Duration with Realistic Setting Incidence proportion    Scen11                                                       seed pool        tau Continued Study Duration with Realistic Setting 1701876972 TRUE HalfNormal                                                 heterog  ESS rob_weight Continued Study Duration with Realistic Setting   Small elir       0.05                                                 nta_event nta_npat Continued Study Duration with Realistic Setting       170      200"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-12---continued-study-duration-with-worst-setting","dir":"Articles","previous_headings":"","what":"Scenario 12 - Continued study duration with Worst Setting","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 12 describes binary endpoint scenario worst case scenario (scenario 4) continued till end proposed study duration. scenario characteristics includes huge censoring, huge noise, little events observed, heterogeneous historical huge prior data conflict. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = NA,   SimStudy_NObsEvt = 400,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.15,   prior_data_conflict = TRUE,   pdc_hz = c(g1 = 0.05, g2 = 0.1),   SAF_TOPIC = \"Scen12\",   seed = 1701878308 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP  TREAT 1_g1 Study#1    1  g1 200    Scen12       193 2145.2002 Scen12 2_g1 Study#2    1  g1 200    Scen12       189 2026.7007 Scen12 3_g1 Study#3    1  g1 200    Scen12       192 2099.1503 Scen12 4_g1 Study#4    1  g1 200    Scen12       193 2200.2265 Scen12 5_g1 Study#5    1  g1 200    Scen12       189 2060.4879 Scen12 6_g1 Study#6    0  g1 200    Scen12       193 3214.6233 Scen12 1_g2 Study#1    1  g2 200    Scen12       196  927.0819 Scen12 2_g2 Study#2    1  g2 200    Scen12       193 1097.0120 Scen12 3_g2 Study#3    1  g2 200    Scen12       196 1112.5535 Scen12 4_g2 Study#4    1  g2 200    Scen12       195 1489.9002 Scen12 5_g2 Study#5    1  g2 200    Scen12       198 1575.7302 Scen12 6_g2 Study#6    0  g2 200    Scen12       191 1811.5262 Scen12 [1] \"With those values our newly created MAP Prior has been updated:\" csv group Continued Study Duration with Worst Setting Scen12.csv    g1                                                         analysis saf_topic Continued Study Duration with Worst Setting Incidence proportion    Scen12                                                   seed pool        tau heterog Continued Study Duration with Worst Setting 1701878308 TRUE HalfNormal   Large                                              ESS rob_weight nta_event nta_npat Continued Study Duration with Worst Setting elir        0.5        30      200"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-13---different-treatment-length","dir":"Articles","previous_headings":"","what":"Scenario 13 - Different treatment length","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 13 describes good scenario different treatment length. violation exchange ability assumption proportions tests fail analysis regular basis, therefore, excluded testing. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 1,   nStudy = 6,   tau = 0.02,   prior_data_conflict = FALSE,   diff_trt_length = TRUE,   pdc_hz = NA,   SAF_TOPIC = \"Scen13\",   seed = 1718356066 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP LENGTH  TREAT 1_g1 Study#1    1  g1 200    Scen13       151 1566.6752    548 Scen13 2_g1 Study#2    1  g1 200    Scen13       150 1494.2869    548 Scen13 3_g1 Study#3    1  g1 200    Scen13       174 1599.3219    730 Scen13 4_g1 Study#4    1  g1 200    Scen13       173 1799.5756    730 Scen13 5_g1 Study#5    1  g1 200    Scen13       185 1708.9438    912 Scen13 6_g1 Study#6    0  g1 200    Scen13       186 1681.4362    912 Scen13 1_g2 Study#1    1  g2 200    Scen13       185  897.0528    548 Scen13 2_g2 Study#2    1  g2 200    Scen13       185  872.8150    548 Scen13 3_g2 Study#3    1  g2 200    Scen13       191  943.3266    730 Scen13 4_g2 Study#4    1  g2 200    Scen13       194  872.9301    730 Scen13 5_g2 Study#5    1  g2 200    Scen13       192 1047.1975    912 Scen13 6_g2 Study#6    0  g2 200    Scen13       198  861.1155    912 Scen13 [1] \"With those values our newly created MAP Prior has been updated:\" csv group             analysis saf_topic Different treatment length Scen13.csv    g1 Incidence proportion    Scen13                                  seed pool        tau heterog  ESS rob_weight Different treatment length 1718356066 TRUE HalfNormal   Large elir        0.1                            nta_event nta_npat Different treatment length       186      200"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"sec-time-to-event-endpoint-results","dir":"Articles","previous_headings":"","what":"Time To Event Endpoint results","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"characteristics thresholds simulation table : Scenario 2 describes test case scenario binary endpoint strong prior data conflict historical current trials. characteristics scenario includes censoring current trial, noise, events observed, homogeneous historical data heavy prior data conflict. characteristics thresholds simulation table : Scenario 3 describes binary endpoint realistic situation dropout rate 5%, 2% tau, events observed 90% power, homogeneous historical data planned prior data conflict. characteristics thresholds simulation table : Scenario 4 describes binary endpoint worst case scenario huge censoring trial, huge noise data, low number events observed 90% power, heterogeneous historical data huge data conflict. characteristics thresholds simulation table : Scenario 5 describes binary endpoint medium heterogeneous scenario historical data, moderate noise 5% tau, moderate censoring 5%, events observed 90%power planned prior data conflict. characteristics thresholds simulation table : Scenario 6 describes binary endpoint scenario huge dropout within current trial, noise 2% tau, event observed 90% power, homogeneous data planned prior data conflict. characteristics thresholds simulation table : Scenario 7 describes binary endpoint scenario high heterogeneity historical data, moderate censoring current trial, moderate noise 2% tau, events observed 90% power, planned prior data conflict. characteristics thresholds simulation table : Scenario 8 describes binary endpoint bad scenario huge censoring current trial, huge noise, little events observed current trial, heterogeneous historical data planned prior data conflict. characteristics thresholds simulation table : Scenario 9 describes binary endpoint good scenario low censoring current trial, small noise, majority events observed homogeneous historical data. characteristics thresholds simulation table : Scenario 10 describes binary endpoint favored control scenario censoring current trial, noise, events observed, homogeneous historical data, heavy prior data conflict hazard ratio favor control group. characteristics thresholds simulation table : Scenario 11 describes binary endpoint realistic situation study continued regardless proposed number events observed. Characteristics scenario includes drop rate 5%, noise 5% tau, homogeneous historical data planned prior data conflict planned. characteristics thresholds simulation table : Scenario 12 describes binary endpoint scenario worst case scenario (scenario 4) continued till end proposed study duration. scenario characteristics includes huge censoring, huge noise, little events observed, heterogeneous historical huge prior data conflict. characteristics thresholds simulation table : Scenario 13 describes good scenario different treatment length. characteristics thresholds simulation table :","code":"# Scen1 SimTestData(   SimStudy_nPat = c(g1 = 300, g2 = 300),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0, time = 12),   SimStudy_accr = 1,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 0.999,   SimStudy_censor_type = 2,   nStudy = 10,   tau = 0,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen1\",   seed = 1699874539 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1   Study#1    1  g1 300     Scen1       299 2828.715 Scen1 2_g1   Study#2    1  g1 300     Scen1       299 2882.367 Scen1 3_g1   Study#3    1  g1 300     Scen1       299 3236.408 Scen1 4_g1   Study#4    1  g1 300     Scen1       299 3085.252 Scen1 5_g1   Study#5    1  g1 300     Scen1       299 2984.353 Scen1 6_g1   Study#6    1  g1 300     Scen1       299 3305.953 Scen1 7_g1   Study#7    1  g1 300     Scen1       299 2975.530 Scen1 8_g1   Study#8    1  g1 300     Scen1       299 3103.969 Scen1 9_g1   Study#9    1  g1 300     Scen1       299 2763.876 Scen1 10_g1 Study#10    0  g1 300     Scen1       299 3044.691 Scen1 1_g2   Study#1    1  g2 300     Scen1       300 1466.836 Scen1 2_g2   Study#2    1  g2 300     Scen1       300 1604.556 Scen1 3_g2   Study#3    1  g2 300     Scen1       300 1428.295 Scen1 4_g2   Study#4    1  g2 300     Scen1       300 1472.222 Scen1 5_g2   Study#5    1  g2 300     Scen1       300 1678.517 Scen1 6_g2   Study#6    1  g2 300     Scen1       300 1504.812 Scen1 7_g2   Study#7    1  g2 300     Scen1       300 1626.479 Scen1 8_g2   Study#8    1  g2 300     Scen1       300 1480.283 Scen1 9_g2   Study#9    1  g2 300     Scen1       300 1644.251 Scen1 10_g2 Study#10    0  g2 300     Scen1       300 1519.465 Scen1 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic Best Case Scenario Scen01.csv    g1 Exposure-adjusted AE rate    Scen01                          seed pool        tau heterog  ESS rob_weight rob_mean Best Case Scenario 1699874539 TRUE HalfNormal   Small elir       0.05      0.1                    nta_event nta_time Best Case Scenario       100     1000 # Scen2 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.3),   SimStudy_dropout = c(rate = 0, time = 12),   SimStudy_accr = 1,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 0.9,   SimStudy_censor_type = 2,   nStudy = 10,   tau = 0.01,   prior_data_conflict = TRUE,   pdc_hz = c(g1 = 0.4, g2 = 0.05),   SAF_TOPIC = \"Scen2\",   seed = 1701611344 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP TREAT 1_g1   Study#1    1  g1 200     Scen2       161 1530.2128 Scen2 2_g1   Study#2    1  g1 200     Scen2       162 1528.7454 Scen2 3_g1   Study#3    1  g1 200     Scen2       160 1660.3443 Scen2 4_g1   Study#4    1  g1 200     Scen2       161 1840.7538 Scen2 5_g1   Study#5    1  g1 200     Scen2       162 1605.1504 Scen2 6_g1   Study#6    1  g1 200     Scen2       164 1496.5477 Scen2 7_g1   Study#7    1  g1 200     Scen2       161 1622.6838 Scen2 8_g1   Study#8    1  g1 200     Scen2       162 1575.8092 Scen2 9_g1   Study#9    1  g1 200     Scen2       161 1638.6499 Scen2 10_g1 Study#10    0  g1 200     Scen2       200  439.5240 Scen2 1_g2   Study#1    1  g2 200     Scen2       199  723.4652 Scen2 2_g2   Study#2    1  g2 200     Scen2       198  725.3088 Scen2 3_g2   Study#3    1  g2 200     Scen2       200  633.6027 Scen2 4_g2   Study#4    1  g2 200     Scen2       199  631.2705 Scen2 5_g2   Study#5    1  g2 200     Scen2       198  701.9784 Scen2 6_g2   Study#6    1  g2 200     Scen2       196  705.4184 Scen2 7_g2   Study#7    1  g2 200     Scen2       199  680.0606 Scen2 8_g2   Study#8    1  g2 200     Scen2       198  704.2055 Scen2 9_g2   Study#9    1  g2 200     Scen2       199  727.2699 Scen2 10_g2 Study#10    0  g2 200     Scen2       160 3910.1011 Scen2 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic Strong Prior Data Conflict Scen02.csv    g2 Exposure-adjusted AE rate    Scen02                                  seed pool        tau heterog  ESS rob_weight Strong Prior Data Conflict 1701611344 TRUE HalfNormal   Small elir        0.8                            rob_mean nta_event nta_time Strong Prior Data Conflict   0.3854       200      518 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.02,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen3\",   seed = 1701621384 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen3        30 282.8273 Scen3 2_g1 Study#2    1  g1 200     Scen3        35 345.5776 Scen3 3_g1 Study#3    1  g1 200     Scen3        32 355.6786 Scen3 4_g1 Study#4    1  g1 200     Scen3        35 409.5392 Scen3 5_g1 Study#5    1  g1 200     Scen3        36 207.1725 Scen3 6_g1 Study#6    0  g1 200     Scen3        40 291.3027 Scen3 1_g2 Study#1    1  g2 200     Scen3        60 259.6821 Scen3 2_g2 Study#2    1  g2 200     Scen3        52 268.0612 Scen3 3_g2 Study#3    1  g2 200     Scen3        57 237.5458 Scen3 4_g2 Study#4    1  g2 200     Scen3        54 359.4474 Scen3 5_g2 Study#5    1  g2 200     Scen3        52 170.1687 Scen3 6_g2 Study#6    0  g2 200     Scen3        50 266.0703 Scen3 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic Realistic scenario Scen03.csv    g1 Exposure-adjusted AE rate    Scen03                          seed pool        tau     heterog  ESS rob_weight Realistic scenario 1701621384 TRUE HalfNormal Substantial elir       0.25                    rob_mean nta_event nta_time Realistic scenario   0.0944        31   328.47 SimTestData(   SimStudy_nPat = c(g1 = 50, g2 = 100),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.2, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 112,   SimStudy_censor_type = 2,   nStudy = 3,   tau = 0.15,   prior_data_conflict = TRUE,   pdc_hz = c(g1 = 0.05, g2 = 0.1),   SAF_TOPIC = \"Scen4\",   seed = 1701626683 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1  50     Scen4        28 197.5691 Scen4 2_g1 Study#2    1  g1  50     Scen4        27 237.3923 Scen4 3_g1 Study#3    0  g1  50     Scen4        23 425.0280 Scen4 1_g2 Study#1    1  g2 100     Scen4        73 283.1671 Scen4 2_g2 Study#2    1  g2 100     Scen4        73 334.8827 Scen4 3_g2 Study#3    0  g2 100     Scen4        70 750.5857 Scen4 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic worst Case Scenario Scen04.csv    g1 Exposure-adjusted AE rate    Scen04                           seed pool        tau    heterog  ESS rob_weight worst Case Scenario 1701626683 TRUE HalfNormal Very Large elir       0.25                     rob_mean nta_event nta_time worst Case Scenario   0.0539        31   328.47 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 1,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.05,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen5\",   seed = 1701628373 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen5        24 336.2761 Scen5 2_g1 Study#2    1  g1 200     Scen5        35 328.5856 Scen5 3_g1 Study#3    1  g1 200     Scen5        26 319.0432 Scen5 4_g1 Study#4    1  g1 200     Scen5        36 319.4839 Scen5 5_g1 Study#5    1  g1 200     Scen5        39 282.5063 Scen5 6_g1 Study#6    0  g1 200     Scen5        25 289.3660 Scen5 1_g2 Study#1    1  g2 200     Scen5        68 295.3881 Scen5 2_g2 Study#2    1  g2 200     Scen5        55 310.0651 Scen5 3_g2 Study#3    1  g2 200     Scen5        63 290.2667 Scen5 4_g2 Study#4    1  g2 200     Scen5        54 288.7203 Scen5 5_g2 Study#5    1  g2 200     Scen5        52 283.8704 Scen5 6_g2 Study#6    0  g2 200     Scen5        66 263.6880 Scen5 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis Heterogeneity Data (Medium) Scen05.csv    g1 Exposure-adjusted AE rate                             saf_topic       seed pool        tau heterog  ESS Heterogeneity Data (Medium)    Scen05 1701628373 TRUE HalfNormal   Large elir                             rob_weight rob_mean nta_event nta_time Heterogeneity Data (Medium)        0.2   0.0865        25      289 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.3, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 95,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.02,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen6\",   seed = 1701628373 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen6        26 291.6589 Scen6 2_g1 Study#2    1  g1 200     Scen6        27 225.3005 Scen6 3_g1 Study#3    1  g1 200     Scen6        28 292.3146 Scen6 4_g1 Study#4    1  g1 200     Scen6        28 268.4692 Scen6 5_g1 Study#5    1  g1 200     Scen6        40 212.6690 Scen6 6_g1 Study#6    0  g1 200     Scen6        24 198.0645 Scen6 1_g2 Study#1    1  g2 200     Scen6        56 226.4060 Scen6 2_g2 Study#2    1  g2 200     Scen6        52 203.6631 Scen6 3_g2 Study#3    1  g2 200     Scen6        55 255.6490 Scen6 4_g2 Study#4    1  g2 200     Scen6        47 221.9167 Scen6 5_g2 Study#5    1  g2 200     Scen6        45 238.6339 Scen6 6_g2 Study#6    0  g2 200     Scen6        54 219.5831 Scen6 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic       seed High Dropout Scen06.csv    g1 Exposure-adjusted AE rate    Scen06 1701628373              pool        tau  heterog  ESS rob_weight rob_mean nta_event High Dropout TRUE HalfNormal Moderate elir       0.14   0.1204        31              nta_time High Dropout      257 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.15,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen7\",   seed = 1701416989 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen7        32 222.47360 Scen7 2_g1 Study#2    1  g1 200     Scen7        27 270.34094 Scen7 3_g1 Study#3    1  g1 200     Scen7        32 271.08747 Scen7 4_g1 Study#4    1  g1 200     Scen7        36 116.93497 Scen7 5_g1 Study#5    1  g1 200     Scen7        29 111.37228 Scen7 6_g1 Study#6    0  g1 200     Scen7        23 163.68689 Scen7 1_g2 Study#1    1  g2 200     Scen7        59 189.49417 Scen7 2_g2 Study#2    1  g2 200     Scen7        62 284.62991 Scen7 3_g2 Study#3    1  g2 200     Scen7        58 210.80011 Scen7 4_g2 Study#4    1  g2 200     Scen7        56  77.53109 Scen7 5_g2 Study#5    1  g2 200     Scen7        62 118.22857 Scen7 6_g2 Study#6    0  g2 200     Scen7        68  97.68813 Scen7 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic High Heterogenity Scen07.csv    g1 Exposure-adjusted AE rate    Scen07                         seed pool        tau    heterog  ESS rob_weight High Heterogenity 1701416989 TRUE HalfNormal Very Large elir        0.2                   rob_mean nta_event nta_time High Heterogenity     0.19        35      200 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.3, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.15,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen8\",   seed = 1701652217 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen8        22 297.7669 Scen8 2_g1 Study#2    1  g1 200     Scen8        31 298.1832 Scen8 3_g1 Study#3    1  g1 200     Scen8        21 307.9312 Scen8 4_g1 Study#4    1  g1 200     Scen8        21 379.2739 Scen8 5_g1 Study#5    1  g1 200     Scen8        28 405.2051 Scen8 6_g1 Study#6    0  g1 200     Scen8        30 368.8481 Scen8 1_g2 Study#1    1  g2 200     Scen8        53 234.0924 Scen8 2_g2 Study#2    1  g2 200     Scen8        45 226.9392 Scen8 3_g2 Study#3    1  g2 200     Scen8        55 211.8717 Scen8 4_g2 Study#4    1  g2 200     Scen8        56 348.7668 Scen8 5_g2 Study#5    1  g2 200     Scen8        46 375.9676 Scen8 6_g2 Study#6    0  g2 200     Scen8        45 284.3348 Scen8 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic       seed Bad Scenario Scen08.csv    g1 Exposure-adjusted AE rate    Scen08 1701652217              pool        tau heterog  ESS rob_weight rob_mean nta_event Bad Scenario TRUE HalfNormal   Large elir        0.2   0.0741        35              nta_time Bad Scenario      338 SimTestData(   SimStudy_nPat = c(g1 = 300, g2 = 300),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 24,   SimStudy_NObsEvt = 0.999,   SimStudy_censor_type = 1,   nStudy = 8,   tau = 0.01,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen9\",   seed = 1701655293 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 300     Scen9       260 2838.989 Scen9 2_g1 Study#2    1  g1 300     Scen9       259 2624.533 Scen9 3_g1 Study#3    1  g1 300     Scen9       251 2933.272 Scen9 4_g1 Study#4    1  g1 300     Scen9       251 2984.729 Scen9 5_g1 Study#5    1  g1 300     Scen9       259 2667.259 Scen9 6_g1 Study#6    1  g1 300     Scen9       265 2774.955 Scen9 7_g1 Study#7    1  g1 300     Scen9       255 2665.750 Scen9 8_g1 Study#8    0  g1 300     Scen9       261 2691.265 Scen9 1_g2 Study#1    1  g2 300     Scen9       292 1550.852 Scen9 2_g2 Study#2    1  g2 300     Scen9       295 1646.227 Scen9 3_g2 Study#3    1  g2 300     Scen9       297 1360.433 Scen9 4_g2 Study#4    1  g2 300     Scen9       289 1676.768 Scen9 5_g2 Study#5    1  g2 300     Scen9       294 1678.219 Scen9 6_g2 Study#6    1  g2 300     Scen9       295 1628.496 Scen9 7_g2 Study#7    1  g2 300     Scen9       295 1628.708 Scen9 8_g2 Study#8    0  g2 300     Scen9       295 1486.654 Scen9 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic       seed Good Scenario Scen09.csv    g1 Exposure-adjusted AE rate    Scen09 1701655293               pool        tau heterog  ESS rob_weight rob_mean nta_event Good Scenario TRUE HalfNormal   Small elir       0.05   0.0926        92               nta_time Good Scenario     1000 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.2, g2 = 0.1),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.02,   prior_data_conflict = TRUE,   pdc_hz = 1.2,   SAF_TOPIC = \"Scen10\",   seed = 1701673095 ) Warning in rexp(nPat[i], hz[i]): NAs produced STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE    TOT_EXP  TREAT 1_g1 Study#1    1  g1 200    Scen10        54 234.482445 Scen10 2_g1 Study#2    1  g1 200    Scen10        42 200.954605 Scen10 3_g1 Study#3    1  g1 200    Scen10        59 233.239862 Scen10 4_g1 Study#4    1  g1 200    Scen10        51 204.363002 Scen10 5_g1 Study#5    1  g1 200    Scen10        52 170.728016 Scen10 6_g1 Study#6    0  g1 200    Scen10        93  -6.482995 Scen10 1_g2 Study#1    1  g2 200    Scen10        36 282.421760 Scen10 2_g2 Study#2    1  g2 200    Scen10        46 214.300246 Scen10 3_g2 Study#3    1  g2 200    Scen10        32 318.335395 Scen10 4_g2 Study#4    1  g2 200    Scen10        37 243.939964 Scen10 5_g2 Study#5    1  g2 200    Scen10        39 244.166712 Scen10 6_g2 Study#6    0  g2 200    Scen10        NA         NA Scen10 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic       seed Favored Control Scen10.csv    g1 Exposure-adjusted AE rate    Scen10 1701673095                 pool        tau heterog  ESS rob_weight rob_mean nta_event Favored Control TRUE HalfNormal   Small elir        0.6   0.2472       150                 nta_time Favored Control      200 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 24,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 1,   nStudy = 6,   tau = 0.02,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen11\",   seed = 1701876972 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP  TREAT 1_g1 Study#1    1  g1 200    Scen11       170 1871.1930 Scen11 2_g1 Study#2    1  g1 200    Scen11       173 1630.1105 Scen11 3_g1 Study#3    1  g1 200    Scen11       168 1744.6636 Scen11 4_g1 Study#4    1  g1 200    Scen11       170 1904.9560 Scen11 5_g1 Study#5    1  g1 200    Scen11       166 1748.6775 Scen11 6_g1 Study#6    0  g1 200    Scen11       162 1879.6921 Scen11 1_g2 Study#1    1  g2 200    Scen11       191  910.6017 Scen11 2_g2 Study#2    1  g2 200    Scen11       192  957.8531 Scen11 3_g2 Study#3    1  g2 200    Scen11       196  922.9765 Scen11 4_g2 Study#4    1  g2 200    Scen11       198  927.3806 Scen11 5_g2 Study#5    1  g2 200    Scen11       193 1027.3669 Scen11 6_g2 Study#6    0  g2 200    Scen11       196 1068.8192 Scen11 [1] \"With those values our newly created MAP Prior has been updated:\" csv group Continued study duration with Realistic Setting Scen11.csv    g1                                                                  analysis Continued study duration with Realistic Setting Exposure-adjusted AE rate                                                 saf_topic       seed pool Continued study duration with Realistic Setting    Scen11 1701876972 TRUE                                                        tau heterog  ESS Continued study duration with Realistic Setting HalfNormal   Small elir                                                 rob_weight rob_mean nta_event Continued study duration with Realistic Setting       0.05   0.0952        95                                                 nta_time Continued study duration with Realistic Setting     1000 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = NA,   SimStudy_NObsEvt = 400,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.15,   prior_data_conflict = TRUE,   pdc_hz = c(g1 = 0.05, g2 = 0.1),   SAF_TOPIC = \"Scen12\",   seed = 1701878308 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP  TREAT 1_g1 Study#1    1  g1 200    Scen12       193 2145.2002 Scen12 2_g1 Study#2    1  g1 200    Scen12       189 2026.7007 Scen12 3_g1 Study#3    1  g1 200    Scen12       192 2099.1503 Scen12 4_g1 Study#4    1  g1 200    Scen12       193 2200.2265 Scen12 5_g1 Study#5    1  g1 200    Scen12       189 2060.4879 Scen12 6_g1 Study#6    0  g1 200    Scen12       193 3214.6233 Scen12 1_g2 Study#1    1  g2 200    Scen12       196  927.0819 Scen12 2_g2 Study#2    1  g2 200    Scen12       193 1097.0120 Scen12 3_g2 Study#3    1  g2 200    Scen12       196 1112.5535 Scen12 4_g2 Study#4    1  g2 200    Scen12       195 1489.9002 Scen12 5_g2 Study#5    1  g2 200    Scen12       198 1575.7302 Scen12 6_g2 Study#6    0  g2 200    Scen12       191 1811.5262 Scen12 [1] \"With those values our newly created MAP Prior has been updated:\" csv group Continued study duration with Worst Setting Scen12.csv    g1                                                              analysis saf_topic Continued study duration with Worst Setting Exposure-adjusted AE rate    Scen12                                                   seed pool        tau heterog Continued study duration with Worst Setting 1701878308 TRUE HalfNormal   Large                                              ESS rob_weight rob_mean nta_event Continued study duration with Worst Setting elir        0.5      0.2       200                                             nta_time Continued study duration with Worst Setting     1000 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 1,   nStudy = 6,   tau = 0.02,   prior_data_conflict = FALSE,   diff_trt_length = TRUE,   pdc_hz = NA,   SAF_TOPIC = \"Scen13\",   seed = 1718356066 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP LENGTH  TREAT 1_g1 Study#1    1  g1 200    Scen13       151 1566.6752    548 Scen13 2_g1 Study#2    1  g1 200    Scen13       150 1494.2869    548 Scen13 3_g1 Study#3    1  g1 200    Scen13       174 1599.3219    730 Scen13 4_g1 Study#4    1  g1 200    Scen13       173 1799.5756    730 Scen13 5_g1 Study#5    1  g1 200    Scen13       185 1708.9438    912 Scen13 6_g1 Study#6    0  g1 200    Scen13       186 1681.4362    912 Scen13 1_g2 Study#1    1  g2 200    Scen13       185  897.0528    548 Scen13 2_g2 Study#2    1  g2 200    Scen13       185  872.8150    548 Scen13 3_g2 Study#3    1  g2 200    Scen13       191  943.3266    730 Scen13 4_g2 Study#4    1  g2 200    Scen13       194  872.9301    730 Scen13 5_g2 Study#5    1  g2 200    Scen13       192 1047.1975    912 Scen13 6_g2 Study#6    0  g2 200    Scen13       198  861.1155    912 Scen13 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic Different Study length Scen13.csv    g1 Exposure-adjusted AE rate    Scen13                              seed pool        tau heterog  ESS rob_weight Different Study length 1718356066 TRUE HalfNormal   Large elir        0.1                        rob_mean nta_event nta_time Different Study length      0.2       186     1681"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-1---best-case-scenario-1","dir":"Articles","previous_headings":"","what":"Scenario 1 - Best Case Scenario","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"characteristics thresholds simulation table :","code":"# Scen1 SimTestData(   SimStudy_nPat = c(g1 = 300, g2 = 300),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0, time = 12),   SimStudy_accr = 1,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 0.999,   SimStudy_censor_type = 2,   nStudy = 10,   tau = 0,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen1\",   seed = 1699874539 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1   Study#1    1  g1 300     Scen1       299 2828.715 Scen1 2_g1   Study#2    1  g1 300     Scen1       299 2882.367 Scen1 3_g1   Study#3    1  g1 300     Scen1       299 3236.408 Scen1 4_g1   Study#4    1  g1 300     Scen1       299 3085.252 Scen1 5_g1   Study#5    1  g1 300     Scen1       299 2984.353 Scen1 6_g1   Study#6    1  g1 300     Scen1       299 3305.953 Scen1 7_g1   Study#7    1  g1 300     Scen1       299 2975.530 Scen1 8_g1   Study#8    1  g1 300     Scen1       299 3103.969 Scen1 9_g1   Study#9    1  g1 300     Scen1       299 2763.876 Scen1 10_g1 Study#10    0  g1 300     Scen1       299 3044.691 Scen1 1_g2   Study#1    1  g2 300     Scen1       300 1466.836 Scen1 2_g2   Study#2    1  g2 300     Scen1       300 1604.556 Scen1 3_g2   Study#3    1  g2 300     Scen1       300 1428.295 Scen1 4_g2   Study#4    1  g2 300     Scen1       300 1472.222 Scen1 5_g2   Study#5    1  g2 300     Scen1       300 1678.517 Scen1 6_g2   Study#6    1  g2 300     Scen1       300 1504.812 Scen1 7_g2   Study#7    1  g2 300     Scen1       300 1626.479 Scen1 8_g2   Study#8    1  g2 300     Scen1       300 1480.283 Scen1 9_g2   Study#9    1  g2 300     Scen1       300 1644.251 Scen1 10_g2 Study#10    0  g2 300     Scen1       300 1519.465 Scen1 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic Best Case Scenario Scen01.csv    g1 Exposure-adjusted AE rate    Scen01                          seed pool        tau heterog  ESS rob_weight rob_mean Best Case Scenario 1699874539 TRUE HalfNormal   Small elir       0.05      0.1                    nta_event nta_time Best Case Scenario       100     1000"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-2---strong-prior-data-conflict-1","dir":"Articles","previous_headings":"","what":"Scenario 2 - Strong Prior Data Conflict","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 2 describes test case scenario binary endpoint strong prior data conflict historical current trials. characteristics scenario includes censoring current trial, noise, events observed, homogeneous historical data heavy prior data conflict. characteristics thresholds simulation table :","code":"# Scen2 SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.3),   SimStudy_dropout = c(rate = 0, time = 12),   SimStudy_accr = 1,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 0.9,   SimStudy_censor_type = 2,   nStudy = 10,   tau = 0.01,   prior_data_conflict = TRUE,   pdc_hz = c(g1 = 0.4, g2 = 0.05),   SAF_TOPIC = \"Scen2\",   seed = 1701611344 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP TREAT 1_g1   Study#1    1  g1 200     Scen2       161 1530.2128 Scen2 2_g1   Study#2    1  g1 200     Scen2       162 1528.7454 Scen2 3_g1   Study#3    1  g1 200     Scen2       160 1660.3443 Scen2 4_g1   Study#4    1  g1 200     Scen2       161 1840.7538 Scen2 5_g1   Study#5    1  g1 200     Scen2       162 1605.1504 Scen2 6_g1   Study#6    1  g1 200     Scen2       164 1496.5477 Scen2 7_g1   Study#7    1  g1 200     Scen2       161 1622.6838 Scen2 8_g1   Study#8    1  g1 200     Scen2       162 1575.8092 Scen2 9_g1   Study#9    1  g1 200     Scen2       161 1638.6499 Scen2 10_g1 Study#10    0  g1 200     Scen2       200  439.5240 Scen2 1_g2   Study#1    1  g2 200     Scen2       199  723.4652 Scen2 2_g2   Study#2    1  g2 200     Scen2       198  725.3088 Scen2 3_g2   Study#3    1  g2 200     Scen2       200  633.6027 Scen2 4_g2   Study#4    1  g2 200     Scen2       199  631.2705 Scen2 5_g2   Study#5    1  g2 200     Scen2       198  701.9784 Scen2 6_g2   Study#6    1  g2 200     Scen2       196  705.4184 Scen2 7_g2   Study#7    1  g2 200     Scen2       199  680.0606 Scen2 8_g2   Study#8    1  g2 200     Scen2       198  704.2055 Scen2 9_g2   Study#9    1  g2 200     Scen2       199  727.2699 Scen2 10_g2 Study#10    0  g2 200     Scen2       160 3910.1011 Scen2 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic Strong Prior Data Conflict Scen02.csv    g2 Exposure-adjusted AE rate    Scen02                                  seed pool        tau heterog  ESS rob_weight Strong Prior Data Conflict 1701611344 TRUE HalfNormal   Small elir        0.8                            rob_mean nta_event nta_time Strong Prior Data Conflict   0.3854       200      518"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-3---realistic-scenario-1","dir":"Articles","previous_headings":"","what":"Scenario 3 - Realistic Scenario","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 3 describes binary endpoint realistic situation dropout rate 5%, 2% tau, events observed 90% power, homogeneous historical data planned prior data conflict. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.02,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen3\",   seed = 1701621384 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen3        30 282.8273 Scen3 2_g1 Study#2    1  g1 200     Scen3        35 345.5776 Scen3 3_g1 Study#3    1  g1 200     Scen3        32 355.6786 Scen3 4_g1 Study#4    1  g1 200     Scen3        35 409.5392 Scen3 5_g1 Study#5    1  g1 200     Scen3        36 207.1725 Scen3 6_g1 Study#6    0  g1 200     Scen3        40 291.3027 Scen3 1_g2 Study#1    1  g2 200     Scen3        60 259.6821 Scen3 2_g2 Study#2    1  g2 200     Scen3        52 268.0612 Scen3 3_g2 Study#3    1  g2 200     Scen3        57 237.5458 Scen3 4_g2 Study#4    1  g2 200     Scen3        54 359.4474 Scen3 5_g2 Study#5    1  g2 200     Scen3        52 170.1687 Scen3 6_g2 Study#6    0  g2 200     Scen3        50 266.0703 Scen3 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic Realistic scenario Scen03.csv    g1 Exposure-adjusted AE rate    Scen03                          seed pool        tau     heterog  ESS rob_weight Realistic scenario 1701621384 TRUE HalfNormal Substantial elir       0.25                    rob_mean nta_event nta_time Realistic scenario   0.0944        31   328.47"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-4---worst-case-scenario-1","dir":"Articles","previous_headings":"","what":"Scenario 4 - Worst Case Scenario","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 4 describes binary endpoint worst case scenario huge censoring trial, huge noise data, low number events observed 90% power, heterogeneous historical data huge data conflict. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 50, g2 = 100),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.2, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 112,   SimStudy_censor_type = 2,   nStudy = 3,   tau = 0.15,   prior_data_conflict = TRUE,   pdc_hz = c(g1 = 0.05, g2 = 0.1),   SAF_TOPIC = \"Scen4\",   seed = 1701626683 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1  50     Scen4        28 197.5691 Scen4 2_g1 Study#2    1  g1  50     Scen4        27 237.3923 Scen4 3_g1 Study#3    0  g1  50     Scen4        23 425.0280 Scen4 1_g2 Study#1    1  g2 100     Scen4        73 283.1671 Scen4 2_g2 Study#2    1  g2 100     Scen4        73 334.8827 Scen4 3_g2 Study#3    0  g2 100     Scen4        70 750.5857 Scen4 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic worst Case Scenario Scen04.csv    g1 Exposure-adjusted AE rate    Scen04                           seed pool        tau    heterog  ESS rob_weight worst Case Scenario 1701626683 TRUE HalfNormal Very Large elir       0.25                     rob_mean nta_event nta_time worst Case Scenario   0.0539        31   328.47"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-5---heterogeneous-data-medium-1","dir":"Articles","previous_headings":"","what":"Scenario 5 - Heterogeneous Data (Medium)","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 5 describes binary endpoint medium heterogeneous scenario historical data, moderate noise 5% tau, moderate censoring 5%, events observed 90%power planned prior data conflict. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 1,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.05,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen5\",   seed = 1701628373 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen5        24 336.2761 Scen5 2_g1 Study#2    1  g1 200     Scen5        35 328.5856 Scen5 3_g1 Study#3    1  g1 200     Scen5        26 319.0432 Scen5 4_g1 Study#4    1  g1 200     Scen5        36 319.4839 Scen5 5_g1 Study#5    1  g1 200     Scen5        39 282.5063 Scen5 6_g1 Study#6    0  g1 200     Scen5        25 289.3660 Scen5 1_g2 Study#1    1  g2 200     Scen5        68 295.3881 Scen5 2_g2 Study#2    1  g2 200     Scen5        55 310.0651 Scen5 3_g2 Study#3    1  g2 200     Scen5        63 290.2667 Scen5 4_g2 Study#4    1  g2 200     Scen5        54 288.7203 Scen5 5_g2 Study#5    1  g2 200     Scen5        52 283.8704 Scen5 6_g2 Study#6    0  g2 200     Scen5        66 263.6880 Scen5 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis Heterogeneity Data (Medium) Scen05.csv    g1 Exposure-adjusted AE rate                             saf_topic       seed pool        tau heterog  ESS Heterogeneity Data (Medium)    Scen05 1701628373 TRUE HalfNormal   Large elir                             rob_weight rob_mean nta_event nta_time Heterogeneity Data (Medium)        0.2   0.0865        25      289"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-6---high-dropout-1","dir":"Articles","previous_headings":"","what":"Scenario 6 - High Dropout","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 6 describes binary endpoint scenario huge dropout within current trial, noise 2% tau, event observed 90% power, homogeneous data planned prior data conflict. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.3, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 95,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.02,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen6\",   seed = 1701628373 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen6        26 291.6589 Scen6 2_g1 Study#2    1  g1 200     Scen6        27 225.3005 Scen6 3_g1 Study#3    1  g1 200     Scen6        28 292.3146 Scen6 4_g1 Study#4    1  g1 200     Scen6        28 268.4692 Scen6 5_g1 Study#5    1  g1 200     Scen6        40 212.6690 Scen6 6_g1 Study#6    0  g1 200     Scen6        24 198.0645 Scen6 1_g2 Study#1    1  g2 200     Scen6        56 226.4060 Scen6 2_g2 Study#2    1  g2 200     Scen6        52 203.6631 Scen6 3_g2 Study#3    1  g2 200     Scen6        55 255.6490 Scen6 4_g2 Study#4    1  g2 200     Scen6        47 221.9167 Scen6 5_g2 Study#5    1  g2 200     Scen6        45 238.6339 Scen6 6_g2 Study#6    0  g2 200     Scen6        54 219.5831 Scen6 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic       seed High Dropout Scen06.csv    g1 Exposure-adjusted AE rate    Scen06 1701628373              pool        tau  heterog  ESS rob_weight rob_mean nta_event High Dropout TRUE HalfNormal Moderate elir       0.14   0.1204        31              nta_time High Dropout      257"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-7---high-heterogeneity-1","dir":"Articles","previous_headings":"","what":"Scenario 7 - High Heterogeneity","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 7 describes binary endpoint scenario high heterogeneity historical data, moderate censoring current trial, moderate noise 2% tau, events observed 90% power, planned prior data conflict. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.15,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen7\",   seed = 1701416989 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen7        32 222.47360 Scen7 2_g1 Study#2    1  g1 200     Scen7        27 270.34094 Scen7 3_g1 Study#3    1  g1 200     Scen7        32 271.08747 Scen7 4_g1 Study#4    1  g1 200     Scen7        36 116.93497 Scen7 5_g1 Study#5    1  g1 200     Scen7        29 111.37228 Scen7 6_g1 Study#6    0  g1 200     Scen7        23 163.68689 Scen7 1_g2 Study#1    1  g2 200     Scen7        59 189.49417 Scen7 2_g2 Study#2    1  g2 200     Scen7        62 284.62991 Scen7 3_g2 Study#3    1  g2 200     Scen7        58 210.80011 Scen7 4_g2 Study#4    1  g2 200     Scen7        56  77.53109 Scen7 5_g2 Study#5    1  g2 200     Scen7        62 118.22857 Scen7 6_g2 Study#6    0  g2 200     Scen7        68  97.68813 Scen7 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic High Heterogenity Scen07.csv    g1 Exposure-adjusted AE rate    Scen07                         seed pool        tau    heterog  ESS rob_weight High Heterogenity 1701416989 TRUE HalfNormal Very Large elir        0.2                   rob_mean nta_event nta_time High Heterogenity     0.19        35      200"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-8---bad-scenario-1","dir":"Articles","previous_headings":"","what":"Scenario 8 - Bad Scenario","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 8 describes binary endpoint bad scenario huge censoring current trial, huge noise, little events observed current trial, heterogeneous historical data planned prior data conflict. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.3, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.15,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen8\",   seed = 1701652217 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 200     Scen8        22 297.7669 Scen8 2_g1 Study#2    1  g1 200     Scen8        31 298.1832 Scen8 3_g1 Study#3    1  g1 200     Scen8        21 307.9312 Scen8 4_g1 Study#4    1  g1 200     Scen8        21 379.2739 Scen8 5_g1 Study#5    1  g1 200     Scen8        28 405.2051 Scen8 6_g1 Study#6    0  g1 200     Scen8        30 368.8481 Scen8 1_g2 Study#1    1  g2 200     Scen8        53 234.0924 Scen8 2_g2 Study#2    1  g2 200     Scen8        45 226.9392 Scen8 3_g2 Study#3    1  g2 200     Scen8        55 211.8717 Scen8 4_g2 Study#4    1  g2 200     Scen8        56 348.7668 Scen8 5_g2 Study#5    1  g2 200     Scen8        46 375.9676 Scen8 6_g2 Study#6    0  g2 200     Scen8        45 284.3348 Scen8 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic       seed Bad Scenario Scen08.csv    g1 Exposure-adjusted AE rate    Scen08 1701652217              pool        tau heterog  ESS rob_weight rob_mean nta_event Bad Scenario TRUE HalfNormal   Large elir        0.2   0.0741        35              nta_time Bad Scenario      338"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-9---good-scenario-1","dir":"Articles","previous_headings":"","what":"Scenario 9 - Good Scenario","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 9 describes binary endpoint good scenario low censoring current trial, small noise, majority events observed homogeneous historical data. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 300, g2 = 300),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 24,   SimStudy_NObsEvt = 0.999,   SimStudy_censor_type = 1,   nStudy = 8,   tau = 0.01,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen9\",   seed = 1701655293 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE  TOT_EXP TREAT 1_g1 Study#1    1  g1 300     Scen9       260 2838.989 Scen9 2_g1 Study#2    1  g1 300     Scen9       259 2624.533 Scen9 3_g1 Study#3    1  g1 300     Scen9       251 2933.272 Scen9 4_g1 Study#4    1  g1 300     Scen9       251 2984.729 Scen9 5_g1 Study#5    1  g1 300     Scen9       259 2667.259 Scen9 6_g1 Study#6    1  g1 300     Scen9       265 2774.955 Scen9 7_g1 Study#7    1  g1 300     Scen9       255 2665.750 Scen9 8_g1 Study#8    0  g1 300     Scen9       261 2691.265 Scen9 1_g2 Study#1    1  g2 300     Scen9       292 1550.852 Scen9 2_g2 Study#2    1  g2 300     Scen9       295 1646.227 Scen9 3_g2 Study#3    1  g2 300     Scen9       297 1360.433 Scen9 4_g2 Study#4    1  g2 300     Scen9       289 1676.768 Scen9 5_g2 Study#5    1  g2 300     Scen9       294 1678.219 Scen9 6_g2 Study#6    1  g2 300     Scen9       295 1628.496 Scen9 7_g2 Study#7    1  g2 300     Scen9       295 1628.708 Scen9 8_g2 Study#8    0  g2 300     Scen9       295 1486.654 Scen9 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic       seed Good Scenario Scen09.csv    g1 Exposure-adjusted AE rate    Scen09 1701655293               pool        tau heterog  ESS rob_weight rob_mean nta_event Good Scenario TRUE HalfNormal   Small elir       0.05   0.0926        92               nta_time Good Scenario     1000"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-10---favoured-control-1","dir":"Articles","previous_headings":"","what":"Scenario 10 - Favoured Control","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 10 describes binary endpoint favored control scenario censoring current trial, noise, events observed, homogeneous historical data, heavy prior data conflict hazard ratio favor control group. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.2, g2 = 0.1),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.02,   prior_data_conflict = TRUE,   pdc_hz = 1.2,   SAF_TOPIC = \"Scen10\",   seed = 1701673095 ) Warning in rexp(nPat[i], hz[i]): NAs produced STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE    TOT_EXP  TREAT 1_g1 Study#1    1  g1 200    Scen10        54 234.482445 Scen10 2_g1 Study#2    1  g1 200    Scen10        42 200.954605 Scen10 3_g1 Study#3    1  g1 200    Scen10        59 233.239862 Scen10 4_g1 Study#4    1  g1 200    Scen10        51 204.363002 Scen10 5_g1 Study#5    1  g1 200    Scen10        52 170.728016 Scen10 6_g1 Study#6    0  g1 200    Scen10        93  -6.482995 Scen10 1_g2 Study#1    1  g2 200    Scen10        36 282.421760 Scen10 2_g2 Study#2    1  g2 200    Scen10        46 214.300246 Scen10 3_g2 Study#3    1  g2 200    Scen10        32 318.335395 Scen10 4_g2 Study#4    1  g2 200    Scen10        37 243.939964 Scen10 5_g2 Study#5    1  g2 200    Scen10        39 244.166712 Scen10 6_g2 Study#6    0  g2 200    Scen10        NA         NA Scen10 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic       seed Favored Control Scen10.csv    g1 Exposure-adjusted AE rate    Scen10 1701673095                 pool        tau heterog  ESS rob_weight rob_mean nta_event Favored Control TRUE HalfNormal   Small elir        0.6   0.2472       150                 nta_time Favored Control      200"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-11---continued-study-duration-with-realistic-setting-1","dir":"Articles","previous_headings":"","what":"Scenario 11 - Continued study duration with Realistic Setting","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 11 describes binary endpoint realistic situation study continued regardless proposed number events observed. Characteristics scenario includes drop rate 5%, noise 5% tau, homogeneous historical data planned prior data conflict planned. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 24,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 1,   nStudy = 6,   tau = 0.02,   prior_data_conflict = FALSE,   pdc_hz = NA,   SAF_TOPIC = \"Scen11\",   seed = 1701876972 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP  TREAT 1_g1 Study#1    1  g1 200    Scen11       170 1871.1930 Scen11 2_g1 Study#2    1  g1 200    Scen11       173 1630.1105 Scen11 3_g1 Study#3    1  g1 200    Scen11       168 1744.6636 Scen11 4_g1 Study#4    1  g1 200    Scen11       170 1904.9560 Scen11 5_g1 Study#5    1  g1 200    Scen11       166 1748.6775 Scen11 6_g1 Study#6    0  g1 200    Scen11       162 1879.6921 Scen11 1_g2 Study#1    1  g2 200    Scen11       191  910.6017 Scen11 2_g2 Study#2    1  g2 200    Scen11       192  957.8531 Scen11 3_g2 Study#3    1  g2 200    Scen11       196  922.9765 Scen11 4_g2 Study#4    1  g2 200    Scen11       198  927.3806 Scen11 5_g2 Study#5    1  g2 200    Scen11       193 1027.3669 Scen11 6_g2 Study#6    0  g2 200    Scen11       196 1068.8192 Scen11 [1] \"With those values our newly created MAP Prior has been updated:\" csv group Continued study duration with Realistic Setting Scen11.csv    g1                                                                  analysis Continued study duration with Realistic Setting Exposure-adjusted AE rate                                                 saf_topic       seed pool Continued study duration with Realistic Setting    Scen11 1701876972 TRUE                                                        tau heterog  ESS Continued study duration with Realistic Setting HalfNormal   Small elir                                                 rob_weight rob_mean nta_event Continued study duration with Realistic Setting       0.05   0.0952        95                                                 nta_time Continued study duration with Realistic Setting     1000"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-12---continued-study-duration-with-worst-setting-1","dir":"Articles","previous_headings":"","what":"Scenario 12 - Continued study duration with Worst Setting","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 12 describes binary endpoint scenario worst case scenario (scenario 4) continued till end proposed study duration. scenario characteristics includes huge censoring, huge noise, little events observed, heterogeneous historical huge prior data conflict. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = NA,   SimStudy_NObsEvt = 400,   SimStudy_censor_type = 2,   nStudy = 6,   tau = 0.15,   prior_data_conflict = TRUE,   pdc_hz = c(g1 = 0.05, g2 = 0.1),   SAF_TOPIC = \"Scen12\",   seed = 1701878308 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP  TREAT 1_g1 Study#1    1  g1 200    Scen12       193 2145.2002 Scen12 2_g1 Study#2    1  g1 200    Scen12       189 2026.7007 Scen12 3_g1 Study#3    1  g1 200    Scen12       192 2099.1503 Scen12 4_g1 Study#4    1  g1 200    Scen12       193 2200.2265 Scen12 5_g1 Study#5    1  g1 200    Scen12       189 2060.4879 Scen12 6_g1 Study#6    0  g1 200    Scen12       193 3214.6233 Scen12 1_g2 Study#1    1  g2 200    Scen12       196  927.0819 Scen12 2_g2 Study#2    1  g2 200    Scen12       193 1097.0120 Scen12 3_g2 Study#3    1  g2 200    Scen12       196 1112.5535 Scen12 4_g2 Study#4    1  g2 200    Scen12       195 1489.9002 Scen12 5_g2 Study#5    1  g2 200    Scen12       198 1575.7302 Scen12 6_g2 Study#6    0  g2 200    Scen12       191 1811.5262 Scen12 [1] \"With those values our newly created MAP Prior has been updated:\" csv group Continued study duration with Worst Setting Scen12.csv    g1                                                              analysis saf_topic Continued study duration with Worst Setting Exposure-adjusted AE rate    Scen12                                                   seed pool        tau heterog Continued study duration with Worst Setting 1701878308 TRUE HalfNormal   Large                                              ESS rob_weight rob_mean nta_event Continued study duration with Worst Setting elir        0.5      0.2       200                                             nta_time Continued study duration with Worst Setting     1000"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"scenario-13---different-treatment-length-1","dir":"Articles","previous_headings":"","what":"Scenario 13 - Different treatment length","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"Scenario 13 describes good scenario different treatment length. characteristics thresholds simulation table :","code":"SimTestData(   SimStudy_nPat = c(g1 = 200, g2 = 200),   SimStudy_hz = c(g1 = 0.1, g2 = 0.2),   SimStudy_dropout = c(rate = 0.05, time = 12),   SimStudy_accr = 6,   SimStudy_accr_method = \"Uniform\",   SimStudy_surv_method = \"Exponential\",   SimStudy_intensity = NA,   SimStudy_accr_timepoint = NA,   SimStudy_time_cutoff = 18,   SimStudy_NObsEvt = 93,   SimStudy_censor_type = 1,   nStudy = 6,   tau = 0.02,   prior_data_conflict = FALSE,   diff_trt_length = TRUE,   pdc_hz = NA,   SAF_TOPIC = \"Scen13\",   seed = 1718356066 ) STUDYID HIST ARM   N SAF_TOPIC N_WITH_AE   TOT_EXP LENGTH  TREAT 1_g1 Study#1    1  g1 200    Scen13       151 1566.6752    548 Scen13 2_g1 Study#2    1  g1 200    Scen13       150 1494.2869    548 Scen13 3_g1 Study#3    1  g1 200    Scen13       174 1599.3219    730 Scen13 4_g1 Study#4    1  g1 200    Scen13       173 1799.5756    730 Scen13 5_g1 Study#5    1  g1 200    Scen13       185 1708.9438    912 Scen13 6_g1 Study#6    0  g1 200    Scen13       186 1681.4362    912 Scen13 1_g2 Study#1    1  g2 200    Scen13       185  897.0528    548 Scen13 2_g2 Study#2    1  g2 200    Scen13       185  872.8150    548 Scen13 3_g2 Study#3    1  g2 200    Scen13       191  943.3266    730 Scen13 4_g2 Study#4    1  g2 200    Scen13       194  872.9301    730 Scen13 5_g2 Study#5    1  g2 200    Scen13       192 1047.1975    912 Scen13 6_g2 Study#6    0  g2 200    Scen13       198  861.1155    912 Scen13 [1] \"With those values our newly created MAP Prior has been updated:\" csv group                  analysis saf_topic Different Study length Scen13.csv    g1 Exposure-adjusted AE rate    Scen13                              seed pool        tau heterog  ESS rob_weight Different Study length 1718356066 TRUE HalfNormal   Large elir        0.1                        rob_mean nta_event nta_time Different Study length      0.2       186     1681"},{"path":"https://insightsengineering.github.io/bsafe/articles/Testing_Strategy.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"B-Safe Testing and Validation v. 0.1 for B-Safe v. 0.1","text":"summary, input checks place work encountered errors development user tests. graphics tables displayed correctly. Defined thresholds underwent independent source code review. method implementation source code reviewed statistical analysis plan (see ) showed errors. structural tests passed except scenario 2, 4, 12 proportions scenario 13. Scenario 2, 4 12 (worst scenarios) issues stem problems integration within . Scenario 13 describes different treatment length. two reasons testing proportions therefor excluded. First, estimator incorrect estimand. incidence proportions estimated equal treatment length. Second, , results high variability simulations testing tolerance irresponsibly high. case different treatment duration, recommend using incidence rates. None source code showed discrepancy independent reviewed testing scripts functions app.","code":""},{"path":[]},{"path":"https://insightsengineering.github.io/bsafe/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Alexander Stemke. Author, maintainer. Lars Andersen. Author. Steven Brooks. Author. Lin Zou. Contributor. Lou Whitehead. Contributor. Dunfu Yang. Contributor. Kevin Kunzmann. Contributor. Oliver Sailer. Contributor. Boehringer Ingelheim Pharma GmbH & Co. KG. Copyright holder, funder.","code":""},{"path":"https://insightsengineering.github.io/bsafe/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Stemke , Andersen L, Brooks S (2024). bsafe: package provides utility functions borrowing historical time--event data using MAP priors. R package version 0.1.0, https://github.com/insightsengineering/bsafe/, https://insightsengineering.github.io/bsafe/.","code":"@Manual{,   title = {bsafe: This package provides utility functions for borrowing historical time-to-event data using MAP priors},   author = {Alexander Stemke and Lars Andersen and Steven Brooks},   year = {2024},   note = {R package version 0.1.0,     https://github.com/insightsengineering/bsafe/},   url = {https://insightsengineering.github.io/bsafe/}, }"},{"path":[]},{"path":"https://insightsengineering.github.io/bsafe/reference/add_row.html","id":null,"dir":"Reference","previous_headings":"","what":"Update warning text data frame — add_row","title":"Update warning text data frame — add_row","text":"Adds another row, data missing comparison","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/add_row.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update warning text data frame — add_row","text":"","code":"add_row(df, data_check, topic, group, analysis)"},{"path":"https://insightsengineering.github.io/bsafe/reference/add_row.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update warning text data frame — add_row","text":"df Data frame existing warning texts data_check Output data_available() topic Safety topics group Comparison number analysis Type analysis","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/add_row.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update warning text data frame — add_row","text":"Another row dataframe returning warning texts missing information consequence.","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/ae_events_wrangler.html","id":null,"dir":"Reference","previous_headings":"","what":"Choices for treatment — ae_events_wrangler","title":"Choices for treatment — ae_events_wrangler","text":"function choose treatment","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/ae_events_wrangler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Choices for treatment — ae_events_wrangler","text":"","code":"ae_events_wrangler(input_data, selected_trt)"},{"path":"https://insightsengineering.github.io/bsafe/reference/ae_events_wrangler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Choices for treatment — ae_events_wrangler","text":"input_data raw summary level data selected_trt selection treatment","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/ae_summary_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior Summary Statistics for Safety Topics of Interest — ae_summary_table","title":"Posterior Summary Statistics for Safety Topics of Interest — ae_summary_table","text":"Creates kable table posterior summary statistics safety topic interest. Creates arrays pdf-download file.","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/ae_summary_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior Summary Statistics for Safety Topics of Interest — ae_summary_table","text":"","code":"ae_summary_table(input_data, cb_list_ctrl, cb_list_trt, saf_topic, seed = NA)"},{"path":"https://insightsengineering.github.io/bsafe/reference/ae_summary_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior Summary Statistics for Safety Topics of Interest — ae_summary_table","text":"input_data dataframe data_table_prep() including new trial cb_list_ctrl expects List control Arm indicators cb_list_trt expects List treatment Arm indicators saf_topic Selected safety topic analyze/adverse event interest seed seed","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/ae_summary_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior Summary Statistics for Safety Topics of Interest — ae_summary_table","text":"kable table posterior summary statistics event type rates proportions","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/app_plots.html","id":null,"dir":"Reference","previous_headings":"","what":"App plots — app_plots","title":"App plots — app_plots","text":"includes plots generated app","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/app_plots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"App plots — app_plots","text":"","code":"app_plots(   select_analysis,   map_object,   saf_topic,   select_btrt,   new_trial_analysis,   stat_inf_dist,   mix )"},{"path":"https://insightsengineering.github.io/bsafe/reference/app_plots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"App plots — app_plots","text":"select_analysis event proportions rates map_object MAP Prior object saf_topic Selected safety topic analyze/adverse event interest select_btrt selected treatment arm new_trial_analysis nta stat_inf_dist Data frame statistical information distribution mix mixture distribution object","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/area_under_the_curve.html","id":null,"dir":"Reference","previous_headings":"","what":"Area under the curve — area_under_the_curve","title":"Area under the curve — area_under_the_curve","text":"Interpret area curve","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/area_under_the_curve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Area under the curve — area_under_the_curve","text":"","code":"area_under_the_curve(ae_prop, mix, saf_topic, select_analysis)"},{"path":"https://insightsengineering.github.io/bsafe/reference/area_under_the_curve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Area under the curve — area_under_the_curve","text":"ae_prop Vector quantiles mix mixture distribution object saf_topic Selected safety topic analyze/adverse event interest select_analysis Incidence proportion Exposure-adjusted AE rate","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/array_comp.html","id":null,"dir":"Reference","previous_headings":"","what":"Array Comparison — array_comp","title":"Array Comparison — array_comp","text":"Assigning values sample array_inci_comp","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/array_comp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Array Comparison — array_comp","text":"","code":"array_comp(   ana,   array_comp = NA,   comp,   pr_sample,   topic = topic,   group,   crilb = lb,   criub = ub,   array_ana = NA )"},{"path":"https://insightsengineering.github.io/bsafe/reference/array_comp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Array Comparison — array_comp","text":"ana Type analysis incidence proportions rates array_comp array setup comparisons comp \"Risk Diff\" \"Risk Ratio\" pr_sample posterior sample difference ratio topic Variable analyzed group current comparison group crilb Cri lower bound criub Cri upper bound array_ana Setup analyzed array","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/array_rmix.html","id":null,"dir":"Reference","previous_headings":"","what":"Array rmix — array_rmix","title":"Array rmix — array_rmix","text":"Assigning values rmix object RBesT array_inci","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/array_rmix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Array rmix — array_rmix","text":"","code":"array_rmix(rmix_obj, array, arm, topic, group, lb = lb, ub = ub)"},{"path":"https://insightsengineering.github.io/bsafe/reference/array_rmix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Array rmix — array_rmix","text":"rmix_obj S3 class matrix R RBesT mixture distribution array array setup arm \"Arm \" (treatment) \"Arm B\" (control) topic Safety Topic group Comparison number lb Lower bound credible interval ub Upper bound credible interval","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/check_minmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Beta Dist Update check — check_minmax","title":"Beta Dist Update check — check_minmax","text":"Many unnecessary error occur RBesT Beta Dist parameters <1","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/check_minmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Beta Dist Update check — check_minmax","text":"","code":"check_minmax(r, n)"},{"path":"https://insightsengineering.github.io/bsafe/reference/check_minmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Beta Dist Update check — check_minmax","text":"r Response = alpha n Total = alpha + beta","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/check_minmax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Beta Dist Update check — check_minmax","text":"vector containing alpha beta beta distribution","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/cri_char.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper for credible interval display — cri_char","title":"Helper for credible interval display — cri_char","text":"Put Credible Interval one Character","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/cri_char.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper for credible interval display — cri_char","text":"","code":"cri_char(df = NA)"},{"path":"https://insightsengineering.github.io/bsafe/reference/cri_char.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper for credible interval display — cri_char","text":"df dataframe expected include columns crilb criub","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/cri_char.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper for credible interval display — cri_char","text":"data frame including credible intervals","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/data_available.html","id":null,"dir":"Reference","previous_headings":"","what":"Data availability — data_available","title":"Data availability — data_available","text":"Gives output 4 T/F values whether input data available, ix stands index","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/data_available.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data availability — data_available","text":"","code":"data_available(hist_trt, hist_ctr, trt_current, ctr_current)"},{"path":"https://insightsengineering.github.io/bsafe/reference/data_available.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data availability — data_available","text":"hist_trt Historical treatment data hist_ctr Historical control data trt_current current treatment data ctr_current current control data","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/data_available.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data availability — data_available","text":"vector inform information available","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/data_table_prep.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Table Preparation — data_table_prep","title":"Summary Table Preparation — data_table_prep","text":"Returns dataframe selected safety topic study ID, number patients selected arm, number patients arm least one occurrence adverse event, total exposure patient years exposure-adjusted analysis chosen.","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/data_table_prep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Table Preparation — data_table_prep","text":"","code":"data_table_prep(   input_data,   select_analysis,   saf_topic,   select_btrt,   bool_pooled = FALSE,   current_trial = FALSE,   ae_summary = FALSE )"},{"path":"https://insightsengineering.github.io/bsafe/reference/data_table_prep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Table Preparation — data_table_prep","text":"input_data raw summary level data select_analysis Incidence proportion Exposure-adjusted AE rate saf_topic Selected safety topic analyze/adverse event interest select_btrt selected background treatment bool_pooled Whether study data pooled study number current_trial information whether historical (0) current (1) trial ae_summary historical filtering comparison, default FALSE","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/data_table_prep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Table Preparation — data_table_prep","text":"dataframe selected safety topic study ID, number patients selected arm, number patients arm least one occurrence adverse event, total exposure patient years exposure-adjusted analysis chosen","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/decision_making_density_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot density — decision_making_density_plot","title":"Plot density — decision_making_density_plot","text":"Plot density","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/decision_making_density_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot density — decision_making_density_plot","text":"","code":"decision_making_density_plot(   select_analysis,   stat_inf_dist,   ae_prop,   saf_topic,   select_btrt )"},{"path":"https://insightsengineering.github.io/bsafe/reference/decision_making_density_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot density — decision_making_density_plot","text":"select_analysis Incidence proportion Exposure-adjusted AE rate stat_inf_dist Data frame statistical information distribution ae_prop Vector quantiles saf_topic Selected safety topic analyze/adverse event interest select_btrt selected background treatment","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/forest_plot_display.html","id":null,"dir":"Reference","previous_headings":"","what":"Forest plot display — forest_plot_display","title":"Forest plot display — forest_plot_display","text":"Display Forestplot MAP Prior Tab","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/forest_plot_display.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forest plot display — forest_plot_display","text":"","code":"forest_plot_display(map_object, select_analysis, saf_topic, select_btrt)"},{"path":"https://insightsengineering.github.io/bsafe/reference/forest_plot_display.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forest plot display — forest_plot_display","text":"map_object gMAP element RBesT select_analysis Incidence proportion Exposure-adjusted AE rate saf_topic Selected safety topic analyze/adverse event interest select_btrt Selected background treatment","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/inci_naiv.html","id":null,"dir":"Reference","previous_headings":"","what":"Naive incidence — inci_naiv","title":"Naive incidence — inci_naiv","text":"Gives naive estimation outputs whole data set","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/inci_naiv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Naive incidence — inci_naiv","text":"","code":"inci_naiv(data, array_inci, arm, topic, group)"},{"path":"https://insightsengineering.github.io/bsafe/reference/inci_naiv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Naive incidence — inci_naiv","text":"data Historic Current data array_inci array setup incidence proportions arm \"Arm \" (treatment) \"Arm B\" (control) topic Safety Topic group Comparison number","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/inci_naiv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Naive incidence — inci_naiv","text":"Returns array naive incidence rates","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/input_data_display.html","id":null,"dir":"Reference","previous_headings":"","what":"Display input data — input_data_display","title":"Display input data — input_data_display","text":"Display input data historical data tab","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/input_data_display.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display input data — input_data_display","text":"","code":"input_data_display(data, select_analysis, saf_topic)"},{"path":"https://insightsengineering.github.io/bsafe/reference/input_data_display.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Display input data — input_data_display","text":"data Uploaded Data select_analysis Incidence proportion Exposure-adjusted AE rate saf_topic Selected safety topic analyze/adverse event interest","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/map_prior_func.html","id":null,"dir":"Reference","previous_headings":"","what":"Meta-Analytic-Predictive Analysis for Generalized Linear Models — map_prior_func","title":"Meta-Analytic-Predictive Analysis for Generalized Linear Models — map_prior_func","text":"MAP prior calculation based selected analysis. RBesT used incidence proportion analysis. MAP prior computed using historical data","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/map_prior_func.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Meta-Analytic-Predictive Analysis for Generalized Linear Models — map_prior_func","text":"","code":"map_prior_func(   input_data,   select_analysis,   tau_dist,   adj_tau,   seed = NULL,   testing = FALSE,   ae_summary = FALSE )"},{"path":"https://insightsengineering.github.io/bsafe/reference/map_prior_func.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Meta-Analytic-Predictive Analysis for Generalized Linear Models — map_prior_func","text":"input_data dataframe data_table_prep() select_analysis Incidence proportion Exposure-adjusted AE rate tau_dist assumed distribution tau adj_tau numeric value tau_adjust seed seed input reproducibility testing testing purposes faster MCMC ae_summary historical filtering comparison, default FALSE","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/map_prior_func.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Meta-Analytic-Predictive Analysis for Generalized Linear Models — map_prior_func","text":"S3 object (list) type gMAP incidence proportion analysis vector posterior MCMC samples exposure-adjusted analysis","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/map_prior_function_display.html","id":null,"dir":"Reference","previous_headings":"","what":"Parametric Approximation density display — map_prior_function_display","title":"Parametric Approximation density display — map_prior_function_display","text":"Display parametric approximation mixture density function MAP Prior Tab","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/map_prior_function_display.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parametric Approximation density display — map_prior_function_display","text":"","code":"map_prior_function_display(param_approx, select_analysis)"},{"path":"https://insightsengineering.github.io/bsafe/reference/map_prior_function_display.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parametric Approximation density display — map_prior_function_display","text":"param_approx parametric approximation select_analysis Incidence proportion Exposure-adjusted AE rate","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/mcmc_desc.html","id":null,"dir":"Reference","previous_headings":"","what":"Describe MCMC sample — mcmc_desc","title":"Describe MCMC sample — mcmc_desc","text":"Helper descriptive statistics sample","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/mcmc_desc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Describe MCMC sample — mcmc_desc","text":"","code":"mcmc_desc(   mcmc_obj = NA,   crilb = 0.025,   criub = 0.975,   seed = NA,   trans = FALSE )"},{"path":"https://insightsengineering.github.io/bsafe/reference/mcmc_desc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Describe MCMC sample — mcmc_desc","text":"mcmc_obj mcmc object, general sample vector crilb Lower Bound credible interval criub Upper Bound credible interval seed Seed reproducibility trans Matrix mixture given, sampled . Needed interpretation log(hazard)","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/mcmc_desc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Describe MCMC sample — mcmc_desc","text":"data frame including descriptive statistics","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/mix_distribution_all.html","id":null,"dir":"Reference","previous_headings":"","what":"Distributions for MAP Prior, Robust MAP Prior, Likelihood, or Posterior Distribution — mix_distribution_all","title":"Distributions for MAP Prior, Robust MAP Prior, Likelihood, or Posterior Distribution — mix_distribution_all","text":"function produces samples display different distributions","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/mix_distribution_all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distributions for MAP Prior, Robust MAP Prior, Likelihood, or Posterior Distribution — mix_distribution_all","text":"","code":"mix_distribution_all(   select_analysis,   current_trial_data,   select_dist,   param_approx,   robust_map_object,   post_dist,   seed )"},{"path":"https://insightsengineering.github.io/bsafe/reference/mix_distribution_all.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Distributions for MAP Prior, Robust MAP Prior, Likelihood, or Posterior Distribution — mix_distribution_all","text":"select_analysis Incidence proportion Exposure-adjusted AE rate current_trial_data information whether historical (0) current (1) trial select_dist Choice displayed Robust MAP/MAP/Likelihood/Post param_approx parametric approximation robust_map_object map prior; mixture distribution non-informative component robust_map() post_dist posterior mixture distribution MCMC samples posterior_dist() seed reproduce figures","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/model_summary_display.html","id":null,"dir":"Reference","previous_headings":"","what":"MAP Prior table — model_summary_display","title":"MAP Prior table — model_summary_display","text":"Function display descriptive characteristics MAP prior, mainly MAP Prior tab","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/model_summary_display.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MAP Prior table — model_summary_display","text":"","code":"model_summary_display(   map_object,   select_analysis,   param_approx,   ess_method,   numerical = FALSE )"},{"path":"https://insightsengineering.github.io/bsafe/reference/model_summary_display.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MAP Prior table — model_summary_display","text":"map_object MAP Prior object select_analysis Incidence proportion Exposure-adjusted AE rate param_approx map prior; best fitting mixture model parametric_approx() ess_method ESS Method, currently ELIR available numerical TRUE FALSE, return values Dataframe displayed","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/new_trial_compare.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataframe preparation for plotting robust map prior, likelihood, and posterior distributions — new_trial_compare","title":"Dataframe preparation for plotting robust map prior, likelihood, and posterior distributions — new_trial_compare","text":"Creates dataframe plotting robust map prior, likelihood, posterior distributions","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/new_trial_compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataframe preparation for plotting robust map prior, likelihood, and posterior distributions — new_trial_compare","text":"","code":"new_trial_compare(select_analysis, robust_map_prior, new_v1, new_v2, post_dist)"},{"path":"https://insightsengineering.github.io/bsafe/reference/new_trial_compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dataframe preparation for plotting robust map prior, likelihood, and posterior distributions — new_trial_compare","text":"select_analysis Incidence proportion Exposure-adjusted AE rate robust_map_prior robust map prior; mixture distribution non-informative component robust_map() new_v1 #new_n sample size new trial selected safety topic background treatment new_v2 #new_r number patients least one occurrence AE interest post_dist posterior mixture distribution MCMC samples posterior_dist()","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/new_trial_compare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dataframe preparation for plotting robust map prior, likelihood, and posterior distributions — new_trial_compare","text":"dataframe plotting robust map prior, likelihood, posterior distributions","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/nta_data_conflict_assassment_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Graphic assessment of Prior Data conflict — nta_data_conflict_assassment_plot","title":"Graphic assessment of Prior Data conflict — nta_data_conflict_assassment_plot","text":"Prior data conflict assessment - compare prior, likelihood, posterior NTA Tab","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/nta_data_conflict_assassment_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Graphic assessment of Prior Data conflict — nta_data_conflict_assassment_plot","text":"","code":"nta_data_conflict_assassment_plot(   new_trial_analysis,   saf_topic,   select_btrt,   select_analysis )"},{"path":"https://insightsengineering.github.io/bsafe/reference/nta_data_conflict_assassment_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Graphic assessment of Prior Data conflict — nta_data_conflict_assassment_plot","text":"new_trial_analysis Coordinates nta tab saf_topic Selected safety topic analyze/adverse event interest select_btrt Selected backgroundtreatments select_analysis Incidence proportion Exposure-adjusted AE rate","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/param_mix_density_display.html","id":null,"dir":"Reference","previous_headings":"","what":"Parametric Mix Display — param_mix_density_display","title":"Parametric Mix Display — param_mix_density_display","text":"Display parametric mixture density MAP Prior Tab","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/param_mix_density_display.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parametric Mix Display — param_mix_density_display","text":"","code":"param_mix_density_display(   param_approx,   select_analysis,   saf_topic,   select_btrt )"},{"path":"https://insightsengineering.github.io/bsafe/reference/param_mix_density_display.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parametric Mix Display — param_mix_density_display","text":"param_approx map prior; best fitting mixture model parametric_approx() select_analysis Incidence proportion Exposure-adjusted AE rate saf_topic Selected safety topic analyze/adverse event interest select_btrt selected background treatment","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/parametric_approx.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatic Fitting of Mixtures of Conjugate Distributions to a Sample — parametric_approx","title":"Automatic Fitting of Mixtures of Conjugate Distributions to a Sample — parametric_approx","text":"Fitting series mixtures conjugate distributions sample using Expectation-Maximization. First, Nc 1 component mixture fitted, Nc 2 component mixture, . mixture providing best AIC value selected.","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/parametric_approx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatic Fitting of Mixtures of Conjugate Distributions to a Sample — parametric_approx","text":"","code":"parametric_approx(select_analysis, map_prior)"},{"path":"https://insightsengineering.github.io/bsafe/reference/parametric_approx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automatic Fitting of Mixtures of Conjugate Distributions to a Sample — parametric_approx","text":"select_analysis Incidence proportion Exposure-adjusted AE rate map_prior S3 object (list) type gMAP incidence proportion analysis vector posterior MCMC samples exposure-adjusted analysis","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/parametric_approx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automatic Fitting of Mixtures of Conjugate Distributions to a Sample — parametric_approx","text":"best fitting mixture model, .e., model lowest AIC","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://insightsengineering.github.io/bsafe/reference/posterior_dist.html","id":null,"dir":"Reference","previous_headings":"","what":"Conjugate Posterior Analysis — posterior_dist","title":"Conjugate Posterior Analysis — posterior_dist","text":"Calculates posterior distribution given prior robust_map_prior, prior mixture conjugate distributions. posterior also mixture conjugate distributions. posterior MCMC samples EXNEX analysis exposure-adjusted analysis","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/posterior_dist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conjugate Posterior Analysis — posterior_dist","text":"","code":"posterior_dist(   select_analysis,   robust_map_prior,   new_v1,   new_v2,   input_data,   p_exch = NULL,   nex_mean = NULL,   nex_sd = NULL,   adj_tau = NULL,   seed = NULL )"},{"path":"https://insightsengineering.github.io/bsafe/reference/posterior_dist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conjugate Posterior Analysis — posterior_dist","text":"select_analysis Incidence proportion Exposure-adjusted AE rate robust_map_prior mixture distribution output robust_map() new_v1 first new variable #n proportion #hazard rate rates new_v2 second new variable #r proportion unit information sd rates input_data dataframe data_table_prep() including new trial p_exch probability exchangeable component (use 1-robust_weight) nex_mean Mean Nex part (use robust_mean) nex_sd Standard Deviation Nex part adj_tau numeric value tau tau_adjust() seed reproducibility","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/posterior_dist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conjugate Posterior Analysis — posterior_dist","text":"posterior mixture distribution incidence proportion analysis ","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/preset_stat_table.html","id":null,"dir":"Reference","previous_headings":"","what":"preset table for inference — preset_stat_table","title":"preset table for inference — preset_stat_table","text":"Table preset statistical inference statement","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/preset_stat_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"preset table for inference — preset_stat_table","text":"","code":"preset_stat_table(mix, saf_topic, select_analysis)"},{"path":"https://insightsengineering.github.io/bsafe/reference/preset_stat_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"preset table for inference — preset_stat_table","text":"mix mixture distribution object saf_topic Selected safety topic analyze/adverse event interest select_analysis Incidence proportion Exposure-adjusted AE rate","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/rmix_desc.html","id":null,"dir":"Reference","previous_headings":"","what":"Describe Mixture Distributions — rmix_desc","title":"Describe Mixture Distributions — rmix_desc","text":"Helper descriptive statistics matrix mixture distribution, object RBesT","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/rmix_desc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Describe Mixture Distributions — rmix_desc","text":"","code":"rmix_desc(rmix_obj = NA, crilb = 0.025, criub = 0.975, deci = 4)"},{"path":"https://insightsengineering.github.io/bsafe/reference/rmix_desc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Describe Mixture Distributions — rmix_desc","text":"rmix_obj dataframe containing mixture distribution crilb Lower Bound credible interval criub Upper Bound credible interval deci Number decimals rounding","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/rmix_desc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Describe Mixture Distributions — rmix_desc","text":"data frame including descriptive statistics","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/robust_compare.html","id":null,"dir":"Reference","previous_headings":"","what":"robust_compare — robust_compare","title":"robust_compare — robust_compare","text":"Creates dataframe plotting comparison map prior robust map prior","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/robust_compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"robust_compare — robust_compare","text":"","code":"robust_compare(select_analysis, robust_map_prior, param_approx)"},{"path":"https://insightsengineering.github.io/bsafe/reference/robust_compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"robust_compare — robust_compare","text":"select_analysis Incidence proportion Exposure-adjusted AE rate robust_map_prior robust map prior; mixture distribution non-informative component robust_map() param_approx map prior; best fitting mixture model parametric_approx()","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/robust_compare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"robust_compare — robust_compare","text":"dataframe comparison map prior robust map prior ggplot","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/robust_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Robustify Mixture Priors — robust_map","title":"Robustify Mixture Priors — robust_map","text":"Add non-informative component mixture prior","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/robust_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Robustify Mixture Priors — robust_map","text":"","code":"robust_map(   select_analysis,   param_approx,   input_data,   robust_weight,   robust_mean,   adj_tau,   seed = NULL,   testing = FALSE )"},{"path":"https://insightsengineering.github.io/bsafe/reference/robust_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Robustify Mixture Priors — robust_map","text":"select_analysis Incidence proportion Exposure-adjusted AE rate param_approx map prior; best fitting mixture model parametric_approx() input_data read data robust_weight weight given non-informative component (0 < weight < 1) robust_mean mean non-informative component adj_tau heterogeneity seed seed reproducibility testing faster mcmc testing","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/robust_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Robustify Mixture Priors — robust_map","text":"new mixture distribution extra non-informative component","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/robust_map_prior_mix_dens_display.html","id":null,"dir":"Reference","previous_headings":"","what":"Robust MAP density display — robust_map_prior_mix_dens_display","title":"Robust MAP density display — robust_map_prior_mix_dens_display","text":"Display robust MAP prior mixture density function robust MAP Prior Tab","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/robust_map_prior_mix_dens_display.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Robust MAP density display — robust_map_prior_mix_dens_display","text":"","code":"robust_map_prior_mix_dens_display(robust_map_object, select_analysis)"},{"path":"https://insightsengineering.github.io/bsafe/reference/robust_map_prior_mix_dens_display.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Robust MAP density display — robust_map_prior_mix_dens_display","text":"robust_map_object map prior; mixture distribution non-informative component robust_map() select_analysis Incidence proportion Exposure-adjusted AE rate","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/robust_map_prior_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot comparison MAP vs. robust MAP — robust_map_prior_plot","title":"Plot comparison MAP vs. robust MAP — robust_map_prior_plot","text":"Compare robust MAP prior MAP prior","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/robust_map_prior_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot comparison MAP vs. robust MAP — robust_map_prior_plot","text":"","code":"robust_map_prior_plot(rob_comp, saf_topic, select_btrt, select_analysis)"},{"path":"https://insightsengineering.github.io/bsafe/reference/robust_map_prior_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot comparison MAP vs. robust MAP — robust_map_prior_plot","text":"rob_comp dataframe containing values MAP robust MAP prior saf_topic Selected safety topic analyze/adverse event interest select_btrt selected backgroundtreatment select_analysis Incidence proportion Exposure-adjusted AE rate","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/sampling_all_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataframe with density quantiles — sampling_all_plot","title":"Dataframe with density quantiles — sampling_all_plot","text":"MAP Prior, Robust MAP Prior, Likelihood, Posterior Distribution Samples Decision Making Tab","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/sampling_all_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataframe with density quantiles — sampling_all_plot","text":"","code":"sampling_all_plot(   select_analysis,   select_dist,   param_approx,   new_trial_analysis )"},{"path":"https://insightsengineering.github.io/bsafe/reference/sampling_all_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dataframe with density quantiles — sampling_all_plot","text":"select_analysis Incidence proportion Exposure-adjusted AE rate select_dist Choice displayed Robust MAP/MAP/Likelihood/Post param_approx parametric approximation new_trial_analysis Objects new trial analysis input","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/summary_stat_all_display.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary statistics for robust prior, likelihood, and posterior — summary_stat_all_display","title":"Summary statistics for robust prior, likelihood, and posterior — summary_stat_all_display","text":"Summary statistics robust prior, likelihood, posterior New trial analysis tab","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/summary_stat_all_display.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary statistics for robust prior, likelihood, and posterior — summary_stat_all_display","text":"","code":"summary_stat_all_display(   select_analysis,   robust_map_object,   ess_method,   current_trial_data,   post_dist,   numerical = FALSE,   seed )"},{"path":"https://insightsengineering.github.io/bsafe/reference/summary_stat_all_display.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary statistics for robust prior, likelihood, and posterior — summary_stat_all_display","text":"select_analysis Incidence proportion Exposure-adjusted AE rate robust_map_object map prior; mixture distribution non-informative component robust_map() ess_method ESS Method, currently ELIR available current_trial_data information whether historical (0) current (1) trial post_dist posterior mixture distribution MCMC samples posterior_dist() numerical TRUE FALSE, return values Dataframe displayed seed seed","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/summary_stats_robust_map_prior_display.html","id":null,"dir":"Reference","previous_headings":"","what":"Display Summary Stats — summary_stats_robust_map_prior_display","title":"Display Summary Stats — summary_stats_robust_map_prior_display","text":"Display summary stats robust MAP prior MAP prior Robust MAP tab","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/summary_stats_robust_map_prior_display.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display Summary Stats — summary_stats_robust_map_prior_display","text":"","code":"summary_stats_robust_map_prior_display(   map_object,   select_analysis,   param_approx,   ess_method,   robust_map_object,   rob_ess_method,   numerical = FALSE,   seed )"},{"path":"https://insightsengineering.github.io/bsafe/reference/summary_stats_robust_map_prior_display.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Display Summary Stats — summary_stats_robust_map_prior_display","text":"map_object MAP Prior object select_analysis Chosen Analysis proportion vs. rates param_approx map prior; best fitting mixture model parametric_approx() ess_method Method calculate ESS: Currently 1 available ELIR robust_map_object map prior; mixture distribution non-informative component robust_map() rob_ess_method Method calculate ESS: Currently 1 available ELIR numerical TRUE FALSE, return values Dataframe displayed seed seed reproduce results","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/tau_adjust.html","id":null,"dir":"Reference","previous_headings":"","what":"Tau Adjustment for Amount of Historical Borrowing — tau_adjust","title":"Tau Adjustment for Amount of Historical Borrowing — tau_adjust","text":"Change value tau control amount historical borrowing","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/tau_adjust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tau Adjustment for Amount of Historical Borrowing — tau_adjust","text":"","code":"tau_adjust(select_analysis, hist_borrow)"},{"path":"https://insightsengineering.github.io/bsafe/reference/tau_adjust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tau Adjustment for Amount of Historical Borrowing — tau_adjust","text":"select_analysis Incidence proportion Exposure-adjusted AE rate hist_borrow amount historical borrowing (\"Small\", \"Moderate\", \"Substantial\", \"Large\", \"Large\")","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/tau_adjust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tau Adjustment for Amount of Historical Borrowing — tau_adjust","text":"numeric value tau based selected amount historical borrowing","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/text_prop.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper for incidence proportion display — text_prop","title":"Helper for incidence proportion display — text_prop","text":"Data Frame display proportions %","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/text_prop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper for incidence proportion display — text_prop","text":"","code":"text_prop(stats_mat_prop = NA)"},{"path":"https://insightsengineering.github.io/bsafe/reference/text_prop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper for incidence proportion display — text_prop","text":"stats_mat_prop Matrix statistical information proportional case","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/text_prop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper for incidence proportion display — text_prop","text":"Text display","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/trt_data_wrangler.html","id":null,"dir":"Reference","previous_headings":"","what":"Arm Choices — trt_data_wrangler","title":"Arm Choices — trt_data_wrangler","text":"function choose Arms","code":""},{"path":"https://insightsengineering.github.io/bsafe/reference/trt_data_wrangler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arm Choices — trt_data_wrangler","text":"","code":"trt_data_wrangler(input_data)"},{"path":"https://insightsengineering.github.io/bsafe/reference/trt_data_wrangler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arm Choices — trt_data_wrangler","text":"input_data raw summary level data","code":""},{"path":[]},{"path":"https://insightsengineering.github.io/bsafe/news/index.html","id":"new-features-0-1-0","dir":"Changelog","previous_headings":"","what":"New features","title":"bsafe 0.1.0","text":"Add initializer script.","code":""},{"path":"https://insightsengineering.github.io/bsafe/news/index.html","id":"enhancements-0-1-0","dir":"Changelog","previous_headings":"","what":"Enhancements","title":"bsafe 0.1.0","text":"Documentation use initialize package.","code":""},{"path":"https://insightsengineering.github.io/bsafe/news/index.html","id":"bug-fixes-0-1-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"bsafe 0.1.0","text":"None.","code":""}]
